{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKMq7dp2W15Y",
        "outputId": "2982515e-db44-4dea-f19d-00409031cd47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "Эimport pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBkqaK5bawXN",
        "outputId": "e8c0efa8-0069-4f7b-fa79-eadce449276a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm-QilGISxkt"
      },
      "source": [
        "## 1. Классификация фамилий (RNN)\n",
        "\n",
        "Датасет: https://disk.yandex.ru/d/frNchuaBQVLxyA?w=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdPr92i6k-If"
      },
      "source": [
        "1.1 Используя класс `nn.RNNCell` (абстракцию для отдельного временного шага RNN), реализуйте простейшую рекуррентную сеть Элмана в виде класса `RNN`. Используя созданный класс `RNN`, решите задачу классификации фамилий.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmwO5a5GnCZd"
      },
      "source": [
        "Этот класс RNN представляет собой простую однослойную рекуррентную нейронную сеть (RNN) с использованием ячейки nn.RNNCell. RNN предназначена для обработки последовательности данных, где x представляет собой входные данные размерности (batch_size, seq_len, feature_size). Каждый элемент последовательности обрабатывается на каждом временном шаге, и скрытое состояние обновляется. Модель возвращает тензор всех скрытых состояний"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ir6UUkl6l4tp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn_cell = nn.RNNCell(input_size, hidden_size)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        \"\"\"\n",
        "        x.shape = (batch_size, seq_len, feature_size) - тензор входных данных\n",
        "        h.shape = (batch_size, hidden_size) - тензор со скрытым состоянием RNN\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        x = x.permute(1, 0, 2)\n",
        "\n",
        "        if h is None:\n",
        "            h = torch.zeros(batch_size, self.hidden_size, dtype=x.dtype, device=x.device)\n",
        "\n",
        "        hidden_states = []\n",
        "\n",
        "        # проход по каждому элементу последовательностей s в батче и обновление скрытого состояния\n",
        "        for t in range(seq_len):\n",
        "            h = self.rnn_cell(x[t], h)\n",
        "            hidden_states.append(h)\n",
        "\n",
        "        hidden_states = torch.stack(hidden_states)\n",
        "        hidden_states = hidden_states.permute(1, 0, 2)\n",
        "\n",
        "        return hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fihFN1zl3Ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_surnames = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/surnames.csv')\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, data):\n",
        "        self.idx_to_token, self.token_to_idx = self.build_vocab(data)\n",
        "        self.vocab_len = len(self.idx_to_token)\n",
        "        self.max_seq_len = self.calculate_max_seq_len(data)\n",
        "\n",
        "    def build_vocab(self, data):\n",
        "        tokens = set()\n",
        "        tokens.add('<PAD>')\n",
        "\n",
        "        for surname in data:\n",
        "            tokens.update(surname.lower())\n",
        "\n",
        "        idx_to_token = {idx: token for idx, token in enumerate(tokens, start=0)}\n",
        "        token_to_idx = {token: idx for idx, token in enumerate(tokens, start=0)}\n",
        "\n",
        "        return idx_to_token, token_to_idx\n",
        "\n",
        "    def calculate_max_seq_len(self, data):\n",
        "        return max(len(surname) for surname in data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCNzz0PVl6I_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SurnamesDataset(Dataset):\n",
        "    def __init__(self, X, y, vocab: Vocab):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def vectorize(self, surname):\n",
        "        indices = [self.vocab.token_to_idx.get(char, 0) for char in surname.lower()]\n",
        "\n",
        "        while len(indices) < self.vocab.max_seq_len:\n",
        "            indices.append(self.vocab.token_to_idx['<PAD>'])\n",
        "\n",
        "        return indices[:self.vocab.max_seq_len]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        surname = self.X.iloc[idx]\n",
        "        nationality = self.y.iloc[idx]\n",
        "\n",
        "        vectorized_surname = self.vectorize(surname)\n",
        "        target = nationality\n",
        "\n",
        "        return {'surname': torch.tensor(vectorized_surname,  dtype=torch.long), 'target':torch.tensor(target, dtype=torch.long)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URcp-iDXl911"
      },
      "outputs": [],
      "source": [
        "nationality_to_idx = {nationality: idx for idx, nationality in enumerate(df_surnames['nationality'].unique())}\n",
        "idx_to_nationality = {idx: nationality for idx, nationality in enumerate(df_surnames['nationality'].unique())}\n",
        "df_surnames['nationality'] = df_surnames['nationality'].map(nationality_to_idx)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df_surnames, test_size=0.2, random_state=42)\n",
        "vocab = Vocab(df_surnames['surname'])\n",
        "train_dataset = SurnamesDataset(X=train_df['surname'], y=train_df['nationality'], vocab=vocab)\n",
        "test_dataset = SurnamesDataset(X=test_df['surname'], y=test_df['nationality'], vocab=vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqR3FQ3BmBpH"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dl, optimizer, criterion):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0.0\n",
        "    correct_samples = 0.0\n",
        "\n",
        "    for batch in train_dl:\n",
        "        inputs, targets = batch['surname'], batch['target']\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets.squeeze())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss\n",
        "        total_samples += targets.shape[0]\n",
        "\n",
        "        _, prediction_indices = torch.max(outputs, 1)\n",
        "        correct_samples += torch.sum(prediction_indices == targets)\n",
        "\n",
        "    train_accuracy = float(correct_samples) / total_samples\n",
        "\n",
        "    return total_loss, train_accuracy\n",
        "\n",
        "def test(model, test_dl):\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0.0\n",
        "    correct_samples = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch in test_dl:\n",
        "          inputs, targets = batch['surname'], batch['target']\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, targets.squeeze())\n",
        "          total_loss += loss\n",
        "\n",
        "\n",
        "          total_samples += targets.shape[0]\n",
        "          _, predictions_indices = torch.max(outputs, 1)\n",
        "          correct_samples += torch.sum(predictions_indices==targets)\n",
        "\n",
        "    test_accuracy = correct_samples / total_samples\n",
        "\n",
        "    return total_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_4txVG8ls0i"
      },
      "outputs": [],
      "source": [
        "class SurnameClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, dropout_rate=0.5):\n",
        "        super(SurnameClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = RNN(embedding_dim, hidden_size)\n",
        "        self.h = None\n",
        "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
        "        # self.fc2 = nn.Linear(hidden_size // 8, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.rnn(x, self.h)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc1(x)\n",
        "        # x = F.relu(x)\n",
        "        # x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size = vocab.vocab_len\n",
        "max_seq_len = vocab.max_seq_len\n",
        "embedding_dim = 25\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "# Устанавливаем freeze_embedding в True, чтобы эмбеддинг не обучался\n",
        "model_1_1 = SurnameClassifier(vocab_size, embedding_dim, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_1.parameters(), lr=0.008)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqh--LjCKGXg",
        "outputId": "623a030d-2dfb-4a17-f744-ff19b5f62008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTpxIwwhoGEy",
        "outputId": "ce4a2faa-d72c-4ad4-be9a-8c09f4e96d1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [158.0741], Train_acc: [0.2490], Test Loss: [40.5288], Test_acc: [0.2140]\n",
            "epoch [2]: Train Loss: [157.1440], Train_acc: [0.2464], Test Loss: [40.4462], Test_acc: [0.2687]\n",
            "epoch [3]: Train Loss: [157.3298], Train_acc: [0.2506], Test Loss: [41.0370], Test_acc: [0.1448]\n",
            "epoch [4]: Train Loss: [156.3863], Train_acc: [0.2509], Test Loss: [40.5586], Test_acc: [0.2687]\n",
            "epoch [5]: Train Loss: [156.6301], Train_acc: [0.2568], Test Loss: [40.6278], Test_acc: [0.2687]\n",
            "epoch [6]: Train Loss: [155.8055], Train_acc: [0.2511], Test Loss: [40.3415], Test_acc: [0.2687]\n",
            "epoch [7]: Train Loss: [155.7303], Train_acc: [0.2605], Test Loss: [40.4591], Test_acc: [0.2837]\n",
            "epoch [8]: Train Loss: [153.2867], Train_acc: [0.3013], Test Loss: [38.7414], Test_acc: [0.3238]\n",
            "epoch [9]: Train Loss: [152.0860], Train_acc: [0.3157], Test Loss: [39.5298], Test_acc: [0.2801]\n",
            "epoch [10]: Train Loss: [149.4493], Train_acc: [0.3193], Test Loss: [38.6054], Test_acc: [0.3156]\n",
            "epoch [11]: Train Loss: [147.6778], Train_acc: [0.3240], Test Loss: [38.8282], Test_acc: [0.3092]\n",
            "epoch [12]: Train Loss: [145.6054], Train_acc: [0.3317], Test Loss: [38.8354], Test_acc: [0.3097]\n",
            "epoch [13]: Train Loss: [145.0095], Train_acc: [0.3460], Test Loss: [38.2698], Test_acc: [0.3046]\n",
            "epoch [14]: Train Loss: [145.3035], Train_acc: [0.3438], Test Loss: [38.4676], Test_acc: [0.3279]\n",
            "epoch [15]: Train Loss: [145.5352], Train_acc: [0.3438], Test Loss: [38.1927], Test_acc: [0.3575]\n",
            "epoch [16]: Train Loss: [143.2761], Train_acc: [0.3515], Test Loss: [37.7679], Test_acc: [0.3393]\n",
            "epoch [17]: Train Loss: [144.0868], Train_acc: [0.3481], Test Loss: [38.0966], Test_acc: [0.3479]\n",
            "epoch [18]: Train Loss: [144.0680], Train_acc: [0.3434], Test Loss: [38.0786], Test_acc: [0.3219]\n",
            "epoch [19]: Train Loss: [144.8892], Train_acc: [0.3423], Test Loss: [39.8820], Test_acc: [0.3147]\n",
            "epoch [20]: Train Loss: [145.0541], Train_acc: [0.3401], Test Loss: [38.0636], Test_acc: [0.3333]\n",
            "epoch [21]: Train Loss: [143.7818], Train_acc: [0.3501], Test Loss: [39.0766], Test_acc: [0.3133]\n",
            "epoch [22]: Train Loss: [146.2141], Train_acc: [0.3437], Test Loss: [38.0986], Test_acc: [0.3429]\n",
            "epoch [23]: Train Loss: [144.5807], Train_acc: [0.3481], Test Loss: [37.2125], Test_acc: [0.3502]\n",
            "epoch [24]: Train Loss: [142.9615], Train_acc: [0.3607], Test Loss: [38.0400], Test_acc: [0.3288]\n",
            "epoch [25]: Train Loss: [147.0274], Train_acc: [0.3419], Test Loss: [37.0414], Test_acc: [0.3443]\n",
            "epoch [26]: Train Loss: [143.1642], Train_acc: [0.3550], Test Loss: [37.2049], Test_acc: [0.3657]\n",
            "epoch [27]: Train Loss: [142.4650], Train_acc: [0.3673], Test Loss: [38.2300], Test_acc: [0.3538]\n",
            "epoch [28]: Train Loss: [141.0137], Train_acc: [0.3749], Test Loss: [37.9555], Test_acc: [0.3575]\n",
            "epoch [29]: Train Loss: [142.4193], Train_acc: [0.3718], Test Loss: [36.6603], Test_acc: [0.3670]\n",
            "epoch [30]: Train Loss: [141.0282], Train_acc: [0.3722], Test Loss: [37.4868], Test_acc: [0.3780]\n",
            "CPU times: user 41.1 s, sys: 383 ms, total: 41.5 s\n",
            "Wall time: 42.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_1, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_1, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "sPVi7ar81Ssg",
        "outputId": "23eeb132-dcb6-48c7-d995-1520b9da82c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses_train, label='На обучении', color='blue')\n",
        "plt.plot(losses_test, label='На тесте', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel('Эпохи')\n",
        "plt.ylabel('Значение функции потерь')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SyYtM2t1b37"
      },
      "outputs": [],
      "source": [
        "def vectorize(surname):\n",
        "    indices = [vocab.token_to_idx.get(char, 0) for char in surname.lower()]\n",
        "\n",
        "    while len(indices) < vocab.max_seq_len:\n",
        "        indices.append(vocab.token_to_idx['<PAD>'])\n",
        "\n",
        "    return torch.tensor(indices[:vocab.max_seq_len], dtype=torch.long).view(1, -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58qn22M21UQx",
        "outputId": "5c34a9f0-b3c4-46ab-ff69-5e547cbcd9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: Russian, Вероятность: 81.0540%\n",
            "Страна: Italian, Вероятность: 3.7530%\n",
            "Страна: Polish, Вероятность: 3.7378%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: English, Вероятность: 42.9171%\n",
            "Страна: Russian, Вероятность: 15.6034%\n",
            "Страна: Italian, Вероятность: 8.8110%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict(model, input_surnames):\n",
        "  for input_surname in input_surnames:\n",
        "      vec_input_surname = vectorize(input_surname)\n",
        "      input_tensor = vec_input_surname\n",
        "      print(f'Фамилия: {input_surname}')\n",
        "\n",
        "      with torch.no_grad():\n",
        "          model.eval()\n",
        "          outputs = model(input_tensor)\n",
        "          res = F.softmax(outputs, dim=1)\n",
        "          predictions = sorted(zip(list(nationality_to_idx.keys()), res.flatten()), key=lambda x: x[1], reverse=True)[:3]\n",
        "          for country, prob in predictions:\n",
        "            print(f'Страна: {country}, Вероятность: {prob.item() * 100:.4f}%')\n",
        "          print()\n",
        "\n",
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_1, input_surnames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2MIErKTo9aO"
      },
      "source": [
        "1.2 Замените модуль `RNN` из 1.1 на модули `nn.RNN`, `nn.LSTM` и `nn.GRU` (не забудьте указать аргумент `batch_first=True`). Сравните результаты работы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8TuSuLM4GNB"
      },
      "outputs": [],
      "source": [
        "class SurnameClassifier2(nn.Module):\n",
        "    def __init__(self, module, vocab_size, embedding_dim, hidden_size, output_size, dropout_rate=0.5):\n",
        "        super(SurnameClassifier2, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.h = None\n",
        "        self.rnn = module(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
        "        # self.fc2 = nn.Linear(hidden_size // 8, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, h = self.rnn(x, self.h)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc1(x)\n",
        "        # x = F.relu(x)\n",
        "        # x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdPCCRc-z253"
      },
      "source": [
        "**nn.RNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рекуррентные слои (Recurrent Layers): Эти слои обрабатывают входные данные пошагово, сохраняя внутреннее состояние между шагами. Это позволяет модели учитывать контекст предыдущих входных данных при обработке текущего входа.\n",
        "\n",
        "Внутреннее состояние (Hidden State): Это внутреннее представление, которое модель поддерживает между входами. Оно содержит информацию о предыдущих шагах и передается следующему шагу для учета контекста.\n",
        "\n",
        "На вход:\n",
        " - input_size: Размер входных данных на каждом временном шаге.\n",
        "\n",
        " - hidden_size: Размер скрытого состояния.\n",
        "\n",
        " - num_layers: Количество слоев в RNN. (по умолчанию 1)\n",
        "\n",
        "На выходе:\n",
        " - output: Тензор с выходными данными на каждом временном шаге для каждого элемента батча.\n",
        " - new_hidden_state: Последнее скрытое состояние после обработки последнего временного шага.\n",
        "\n",
        " batch_first = True означает что в тензоре входые данных размерность батча будет первой\n",
        "\n",
        "В обычных RNN информация может быстро забываться или \"размываться\" в процессе передачи через множество временных шагов, известное как проблема затухающего градиента (vanishing gradient problem). Это может затруднить обучение модели учитывать долгосрочные зависимости."
      ],
      "metadata": {
        "id": "uyvQAzWXQ_qi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRXY7ngv-x17"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size = vocab.vocab_len\n",
        "embedding_dim = 25\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "model_1_2_rnn = SurnameClassifier2(nn.RNN, vocab_size, embedding_dim, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_2_rnn.parameters(), lr=0.008)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtpX8uZYInbj",
        "outputId": "a76549ef-6ccf-4463-e135-a402c51a44d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [159.6864], Train_acc: [0.2526], Test Loss: [40.3417], Test_acc: [0.2687]\n",
            "epoch [2]: Train Loss: [156.6506], Train_acc: [0.2737], Test Loss: [41.3075], Test_acc: [0.2691]\n",
            "epoch [3]: Train Loss: [155.6695], Train_acc: [0.2791], Test Loss: [40.6017], Test_acc: [0.3238]\n",
            "epoch [4]: Train Loss: [156.4996], Train_acc: [0.2689], Test Loss: [40.0941], Test_acc: [0.2855]\n",
            "epoch [5]: Train Loss: [152.0583], Train_acc: [0.3189], Test Loss: [37.3780], Test_acc: [0.3693]\n",
            "epoch [6]: Train Loss: [145.9227], Train_acc: [0.3643], Test Loss: [37.9186], Test_acc: [0.3716]\n",
            "epoch [7]: Train Loss: [141.5801], Train_acc: [0.3887], Test Loss: [37.1488], Test_acc: [0.3889]\n",
            "epoch [8]: Train Loss: [141.9906], Train_acc: [0.3848], Test Loss: [38.3351], Test_acc: [0.3356]\n",
            "epoch [9]: Train Loss: [141.1739], Train_acc: [0.3818], Test Loss: [36.3197], Test_acc: [0.3907]\n",
            "epoch [10]: Train Loss: [142.0874], Train_acc: [0.3833], Test Loss: [37.7711], Test_acc: [0.3839]\n",
            "epoch [11]: Train Loss: [143.7490], Train_acc: [0.3837], Test Loss: [38.6318], Test_acc: [0.3593]\n",
            "epoch [12]: Train Loss: [150.8015], Train_acc: [0.3345], Test Loss: [38.5322], Test_acc: [0.3748]\n",
            "epoch [13]: Train Loss: [147.5338], Train_acc: [0.3690], Test Loss: [38.5666], Test_acc: [0.3707]\n",
            "epoch [14]: Train Loss: [142.7125], Train_acc: [0.3874], Test Loss: [36.9447], Test_acc: [0.3834]\n",
            "epoch [15]: Train Loss: [144.3715], Train_acc: [0.3774], Test Loss: [37.5128], Test_acc: [0.3320]\n",
            "epoch [16]: Train Loss: [141.5818], Train_acc: [0.3829], Test Loss: [38.0322], Test_acc: [0.3807]\n",
            "epoch [17]: Train Loss: [143.2343], Train_acc: [0.3811], Test Loss: [36.8535], Test_acc: [0.3821]\n",
            "epoch [18]: Train Loss: [141.8909], Train_acc: [0.3882], Test Loss: [37.4968], Test_acc: [0.3857]\n",
            "epoch [19]: Train Loss: [139.8259], Train_acc: [0.3925], Test Loss: [36.1362], Test_acc: [0.3939]\n",
            "epoch [20]: Train Loss: [137.9635], Train_acc: [0.3940], Test Loss: [36.7731], Test_acc: [0.3411]\n",
            "epoch [21]: Train Loss: [138.0765], Train_acc: [0.3957], Test Loss: [35.6982], Test_acc: [0.3916]\n",
            "epoch [22]: Train Loss: [138.6240], Train_acc: [0.3983], Test Loss: [36.7562], Test_acc: [0.3552]\n",
            "epoch [23]: Train Loss: [138.4341], Train_acc: [0.3872], Test Loss: [37.3732], Test_acc: [0.3766]\n",
            "epoch [24]: Train Loss: [139.7269], Train_acc: [0.3893], Test Loss: [37.0344], Test_acc: [0.3584]\n",
            "epoch [25]: Train Loss: [137.7959], Train_acc: [0.3946], Test Loss: [36.5728], Test_acc: [0.3966]\n",
            "epoch [26]: Train Loss: [136.1891], Train_acc: [0.4041], Test Loss: [35.9820], Test_acc: [0.3998]\n",
            "epoch [27]: Train Loss: [136.8599], Train_acc: [0.4024], Test Loss: [37.0295], Test_acc: [0.3971]\n",
            "epoch [28]: Train Loss: [136.9177], Train_acc: [0.4037], Test Loss: [36.0100], Test_acc: [0.3825]\n",
            "epoch [29]: Train Loss: [135.4923], Train_acc: [0.4113], Test Loss: [35.6529], Test_acc: [0.4103]\n",
            "epoch [30]: Train Loss: [136.1706], Train_acc: [0.4065], Test Loss: [35.7023], Test_acc: [0.3989]\n",
            "CPU times: user 34.9 s, sys: 261 ms, total: 35.1 s\n",
            "Wall time: 36.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_2_rnn, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_2_rnn, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P34jV3RPNEAN",
        "outputId": "291566f3-c01b-4eaf-e948-3cc3e04b74f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: Russian, Вероятность: 93.0345%\n",
            "Страна: Greek, Вероятность: 2.7456%\n",
            "Страна: Czech, Вероятность: 1.2471%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: Russian, Вероятность: 44.8358%\n",
            "Страна: English, Вероятность: 16.7390%\n",
            "Страна: Greek, Вероятность: 7.2187%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_2_rnn, input_surnames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MezYEAoEM09V"
      },
      "source": [
        "**nn.LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.LSTM в библиотеке PyTorch представляет собой рекуррентный слой, реализующий Long Short-Term Memory (LSTM) архитектуру. LSTM является одним из видов рекуррентных нейронных сетей (RNN), предназначенных для работы с последовательными данными, сохраняя информацию о контексте на протяжении времени.\n",
        "\n",
        "Основные компоненты LSTM включают в себя:\n",
        "\n",
        " - Ячейка памяти (Memory Cell): Это место, где модель хранит и обновляет информацию о предыдущих состояниях.\n",
        "\n",
        " - Вентили (Gates): LSTM использует три вентиля - вентиль забывания (Forget Gate), вентиль ввода (Input Gate) и вентиль вывода (Output Gate). Эти вентили контролируют, какая информация должна быть забыта, какая информация должна быть добавлена в ячейку памяти и какая информация должна быть выходом модели.\n",
        "\n",
        " - Скрытое состояние (Hidden State): Это состояние передается от одного временного шага к следующему, и оно представляет собой краткое представление информации о прошлых состояниях.\n",
        "\n",
        "LSTM обеспечивают механизм управления памятью, что делает их более способными к обработке долгосрочных зависимостей и решению проблемы затухающего градиента, которая может возникнуть при использовании обычных RNN."
      ],
      "metadata": {
        "id": "p9cW_XavS_Md"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLgmeKbsNRm9"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size = vocab.vocab_len\n",
        "embedding_dim = 25\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "model_1_2_lstm = SurnameClassifier2(nn.LSTM, vocab_size, embedding_dim, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_2_lstm.parameters(), lr=0.008)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2TwCVOzNcvN",
        "outputId": "ac9202e1-b543-4913-a7ab-6787030b4315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [155.6054], Train_acc: [0.2560], Test Loss: [39.8311], Test_acc: [0.2687]\n",
            "epoch [2]: Train Loss: [145.4001], Train_acc: [0.3444], Test Loss: [35.0008], Test_acc: [0.4308]\n",
            "epoch [3]: Train Loss: [119.4304], Train_acc: [0.5237], Test Loss: [27.7306], Test_acc: [0.5883]\n",
            "epoch [4]: Train Loss: [93.7524], Train_acc: [0.6322], Test Loss: [22.4194], Test_acc: [0.6639]\n",
            "epoch [5]: Train Loss: [75.8946], Train_acc: [0.6926], Test Loss: [19.7598], Test_acc: [0.6899]\n",
            "epoch [6]: Train Loss: [64.7585], Train_acc: [0.7286], Test Loss: [18.3019], Test_acc: [0.7131]\n",
            "epoch [7]: Train Loss: [56.6879], Train_acc: [0.7541], Test Loss: [17.1289], Test_acc: [0.7250]\n",
            "epoch [8]: Train Loss: [50.8942], Train_acc: [0.7757], Test Loss: [17.1503], Test_acc: [0.7222]\n",
            "epoch [9]: Train Loss: [46.8289], Train_acc: [0.7909], Test Loss: [17.2698], Test_acc: [0.7327]\n",
            "epoch [10]: Train Loss: [40.8528], Train_acc: [0.8176], Test Loss: [16.8025], Test_acc: [0.7336]\n",
            "epoch [11]: Train Loss: [40.1168], Train_acc: [0.8177], Test Loss: [17.2351], Test_acc: [0.7400]\n",
            "epoch [12]: Train Loss: [36.1120], Train_acc: [0.8356], Test Loss: [17.4809], Test_acc: [0.7400]\n",
            "epoch [13]: Train Loss: [31.3263], Train_acc: [0.8558], Test Loss: [18.1549], Test_acc: [0.7341]\n",
            "epoch [14]: Train Loss: [29.1214], Train_acc: [0.8632], Test Loss: [18.8552], Test_acc: [0.7322]\n",
            "epoch [15]: Train Loss: [26.4129], Train_acc: [0.8818], Test Loss: [18.1237], Test_acc: [0.7354]\n",
            "epoch [16]: Train Loss: [25.3858], Train_acc: [0.8837], Test Loss: [19.9968], Test_acc: [0.7459]\n",
            "epoch [17]: Train Loss: [25.6593], Train_acc: [0.8815], Test Loss: [19.6298], Test_acc: [0.7423]\n",
            "epoch [18]: Train Loss: [23.4187], Train_acc: [0.8893], Test Loss: [19.0936], Test_acc: [0.7473]\n",
            "epoch [19]: Train Loss: [20.2805], Train_acc: [0.9019], Test Loss: [20.6377], Test_acc: [0.7345]\n",
            "epoch [20]: Train Loss: [17.6728], Train_acc: [0.9172], Test Loss: [20.8109], Test_acc: [0.7363]\n",
            "epoch [21]: Train Loss: [16.5117], Train_acc: [0.9199], Test Loss: [20.9123], Test_acc: [0.7368]\n",
            "epoch [22]: Train Loss: [17.4921], Train_acc: [0.9150], Test Loss: [21.7310], Test_acc: [0.7213]\n",
            "epoch [23]: Train Loss: [17.2122], Train_acc: [0.9166], Test Loss: [21.2156], Test_acc: [0.7345]\n",
            "epoch [24]: Train Loss: [16.4836], Train_acc: [0.9203], Test Loss: [22.0401], Test_acc: [0.7313]\n",
            "epoch [25]: Train Loss: [15.8532], Train_acc: [0.9217], Test Loss: [22.0846], Test_acc: [0.7318]\n",
            "epoch [26]: Train Loss: [14.3973], Train_acc: [0.9285], Test Loss: [22.8392], Test_acc: [0.7332]\n",
            "epoch [27]: Train Loss: [14.1957], Train_acc: [0.9291], Test Loss: [22.7072], Test_acc: [0.7327]\n",
            "epoch [28]: Train Loss: [13.5727], Train_acc: [0.9316], Test Loss: [23.1086], Test_acc: [0.7377]\n",
            "epoch [29]: Train Loss: [13.6888], Train_acc: [0.9300], Test Loss: [23.7625], Test_acc: [0.7195]\n",
            "epoch [30]: Train Loss: [12.0029], Train_acc: [0.9385], Test Loss: [23.9162], Test_acc: [0.7295]\n",
            "CPU times: user 59.3 s, sys: 2.56 s, total: 1min 1s\n",
            "Wall time: 1min 2s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_2_lstm, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_2_lstm, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Y1n1MELNczz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8e1c57-8b9d-4ed1-d7aa-6720b7e23b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: Russian, Вероятность: 99.9997%\n",
            "Страна: Chinese, Вероятность: 0.0002%\n",
            "Страна: Japanese, Вероятность: 0.0001%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: Russian, Вероятность: 99.9998%\n",
            "Страна: Japanese, Вероятность: 0.0001%\n",
            "Страна: Greek, Вероятность: 0.0000%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_2_lstm, input_surnames)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.GRU**"
      ],
      "metadata": {
        "id": "OoJNo6V1QI0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.GRU в библиотеке PyTorch представляет собой ещё один тип рекуррентного слоя, реализующий архитектуру Gated Recurrent Unit (GRU). GRU является альтернативой LSTM и также предназначен для работы с последовательными данными, но с более простой архитектурой.\n",
        "\n",
        "Основные компоненты nn.GRU включают в себя:\n",
        "\n",
        " - Скрытое состояние (Hidden State): Передается от одного временного шага к следующему, представляя краткое представление информации о прошлых состояниях.\n",
        "\n",
        " - Вентиль обновления (Update Gate): Определяет, какая часть информации из предыдущего скрытого состояния должна быть обновлена.\n",
        "\n",
        " - Вентиль сброса (Reset Gate): Определяет, какая часть информации из предыдущего скрытого состояния следует быть забыта.\n",
        "\n",
        "GRU проще по структуре по сравнению с LSTM, так как она объединяет вентили обновления и сброса в один вентиль. Это делает GRU более легким для обучения и менее подверженным затуханию градиента в сравнении с некоторыми типами обычных RNN."
      ],
      "metadata": {
        "id": "0Cn89hsTUI8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size = vocab.vocab_len\n",
        "embedding_dim = 25\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "model_1_2_gru = SurnameClassifier2(nn.GRU, vocab_size, embedding_dim, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_2_gru.parameters(), lr=0.008)"
      ],
      "metadata": {
        "id": "rTSTIzxKQMOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_2_gru, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_2_gru, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gB6lQ9ZQMSC",
        "outputId": "940dc5b4-1861-4bfa-f2ea-d07d3e88ebb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [118.9446], Train_acc: [0.5010], Test Loss: [24.5702], Test_acc: [0.5938]\n",
            "epoch [2]: Train Loss: [74.1069], Train_acc: [0.6883], Test Loss: [18.3122], Test_acc: [0.7186]\n",
            "epoch [3]: Train Loss: [58.9592], Train_acc: [0.7458], Test Loss: [17.0417], Test_acc: [0.7222]\n",
            "epoch [4]: Train Loss: [48.0340], Train_acc: [0.7820], Test Loss: [16.2727], Test_acc: [0.7382]\n",
            "epoch [5]: Train Loss: [41.1333], Train_acc: [0.8158], Test Loss: [15.9178], Test_acc: [0.7541]\n",
            "epoch [6]: Train Loss: [34.9128], Train_acc: [0.8396], Test Loss: [16.5321], Test_acc: [0.7532]\n",
            "epoch [7]: Train Loss: [31.2479], Train_acc: [0.8510], Test Loss: [16.7204], Test_acc: [0.7523]\n",
            "epoch [8]: Train Loss: [27.4938], Train_acc: [0.8678], Test Loss: [16.7335], Test_acc: [0.7523]\n",
            "epoch [9]: Train Loss: [23.2186], Train_acc: [0.8897], Test Loss: [16.8178], Test_acc: [0.7564]\n",
            "epoch [10]: Train Loss: [21.5490], Train_acc: [0.8959], Test Loss: [17.3767], Test_acc: [0.7454]\n",
            "epoch [11]: Train Loss: [19.7279], Train_acc: [0.9012], Test Loss: [19.0621], Test_acc: [0.7532]\n",
            "epoch [12]: Train Loss: [19.4035], Train_acc: [0.9060], Test Loss: [18.6182], Test_acc: [0.7404]\n",
            "epoch [13]: Train Loss: [19.0244], Train_acc: [0.9061], Test Loss: [18.9894], Test_acc: [0.7491]\n",
            "epoch [14]: Train Loss: [19.8053], Train_acc: [0.9012], Test Loss: [19.8609], Test_acc: [0.7359]\n",
            "epoch [15]: Train Loss: [19.0699], Train_acc: [0.9106], Test Loss: [20.4178], Test_acc: [0.7309]\n",
            "epoch [16]: Train Loss: [17.7664], Train_acc: [0.9102], Test Loss: [21.1081], Test_acc: [0.7486]\n",
            "epoch [17]: Train Loss: [18.2631], Train_acc: [0.9114], Test Loss: [20.2081], Test_acc: [0.7418]\n",
            "epoch [18]: Train Loss: [18.5056], Train_acc: [0.9063], Test Loss: [20.7962], Test_acc: [0.7523]\n",
            "epoch [19]: Train Loss: [19.7848], Train_acc: [0.9019], Test Loss: [22.9164], Test_acc: [0.7108]\n",
            "epoch [20]: Train Loss: [21.2865], Train_acc: [0.8923], Test Loss: [22.4082], Test_acc: [0.7231]\n",
            "epoch [21]: Train Loss: [22.2920], Train_acc: [0.8933], Test Loss: [22.2321], Test_acc: [0.7259]\n",
            "epoch [22]: Train Loss: [22.8666], Train_acc: [0.8889], Test Loss: [22.5662], Test_acc: [0.7259]\n",
            "epoch [23]: Train Loss: [21.6937], Train_acc: [0.8932], Test Loss: [22.1585], Test_acc: [0.7363]\n",
            "epoch [24]: Train Loss: [19.8444], Train_acc: [0.8959], Test Loss: [22.0638], Test_acc: [0.7336]\n",
            "epoch [25]: Train Loss: [18.2237], Train_acc: [0.9066], Test Loss: [22.7297], Test_acc: [0.7254]\n",
            "epoch [26]: Train Loss: [17.1119], Train_acc: [0.9154], Test Loss: [22.2043], Test_acc: [0.7450]\n",
            "epoch [27]: Train Loss: [17.4591], Train_acc: [0.9117], Test Loss: [23.2019], Test_acc: [0.7231]\n",
            "epoch [28]: Train Loss: [21.6750], Train_acc: [0.8950], Test Loss: [22.1201], Test_acc: [0.7304]\n",
            "epoch [29]: Train Loss: [21.5191], Train_acc: [0.8914], Test Loss: [22.5344], Test_acc: [0.7313]\n",
            "epoch [30]: Train Loss: [19.9071], Train_acc: [0.8971], Test Loss: [22.4339], Test_acc: [0.7368]\n",
            "CPU times: user 1min 7s, sys: 597 ms, total: 1min 7s\n",
            "Wall time: 1min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_2_gru, input_surnames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INjKUuQzQMVv",
        "outputId": "05a476c8-3015-4c62-bcc0-acada98867f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: Russian, Вероятность: 99.9882%\n",
            "Страна: Czech, Вероятность: 0.0095%\n",
            "Страна: Spanish, Вероятность: 0.0008%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: Russian, Вероятность: 99.9679%\n",
            "Страна: English, Вероятность: 0.0251%\n",
            "Страна: Czech, Вероятность: 0.0048%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Структура и вентили:**\n",
        "\n",
        "RNN:\n",
        "\n",
        " - Простая структура с обратной связью между временными шагами.\n",
        " - Нет явных вентилей для контроля потока информации.\n",
        "\n",
        "LSTM:\n",
        "\n",
        " - Три вентиля: вентиль забывания, вентиль ввода и вентиль вывода.\n",
        " - Возможность эффективно управлять памятью и обрабатывать долгосрочные зависимости.\n",
        "\n",
        "GRU:\n",
        "\n",
        " - Один вентиль, объединяющий вентили обновления и сброса.\n",
        " - Более простая структура по сравнению с LSTM.\n",
        "\n",
        "**2. Число параметров:**\n",
        "\n",
        "RNN:\n",
        "\n",
        " - Обычно содержит меньше параметров по сравнению с LSTM и GRU.\n",
        "\n",
        "LSTM:\n",
        "\n",
        " - Обычно имеет больше параметров из-за наличия трех вентилей.\n",
        "\n",
        "GRU:\n",
        "\n",
        " - Требует меньше параметров, что может быть преимуществом при ограниченных вычислительных ресурсах.\n",
        "\n",
        "**3. Обучение:**\n",
        "\n",
        "RNN:\n",
        "\n",
        " - Может сталкиваться с проблемой затухания градиента при обучении на длинных последовательностях.\n",
        "\n",
        "LSTM:\n",
        "\n",
        " - Хорошо справляется с проблемой затухания градиента и обучается лучше на долгосрочных зависимостях.\n",
        "\n",
        "GRU:\n",
        "\n",
        " - Обучается быстрее, чем LSTM, и также менее подвержен проблемам затухания градиента.\n",
        "\n",
        "**4. Выбор в зависимости от задачи:**\n",
        "\n",
        "RNN:\n",
        "\n",
        " - Простота и низкое количество параметров могут быть важными в определенных сценариях.\n",
        "\n",
        "LSTM:\n",
        "\n",
        " - Хорошо подходит для задач, где важны долгосрочные зависимости, такие как обработка естественного языка (NLP).\n",
        "\n",
        "GRU:\n",
        "\n",
        " - Может быть предпочтителен, если вы сталкиваетесь с ограниченными вычислительными ресурсами и хотите простую модель."
      ],
      "metadata": {
        "id": "Q8c8lEzxVagu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9vGEnVZYfAbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6YBam_3t-fO"
      },
      "source": [
        "1.3 Загрузите предобученные эмбеддинги (https://disk.yandex.ru/d/BHuT2tEXr_yBOQ?w=1) в модуль `nn.Embedding` и обучите модели из 1.2."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameClassifier3(nn.Module):\n",
        "    def __init__(self, module, vocab_size, embedding_dim, hidden_size, output_size, vectors, dropout_rate=0.5):\n",
        "        super(SurnameClassifier3, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(vectors, freeze=True)\n",
        "        self.h = None\n",
        "        self.rnn = module(input_size=embedding_dim, hidden_size=hidden_size, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, output_size)\n",
        "        # self.fc2 = nn.Linear(hidden_size // 8, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, h = self.rnn(x, self.h)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc1(x)\n",
        "        # x = F.relu(x)\n",
        "        # x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "MW6Mig2RNxPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMrHPvkGi17c"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/globe_100_rows.txt'\n",
        "\n",
        "word_vectors = {}\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        parts = line.split()\n",
        "        word = parts[0]\n",
        "        vector = [float(val) for val in parts[1:]]\n",
        "        word_vectors[word] = vector\n",
        "\n",
        "words = list(word_vectors.keys())\n",
        "vectors = torch.FloatTensor(list(word_vectors.values()))\n",
        "embedding_matrix = nn.Embedding.from_pretrained(vectors, freeze=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygV2_tUNQOAJ",
        "outputId": "66ba1580-94eb-44a3-bc68-f78d86a91cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " ',',\n",
              " '.',\n",
              " 'of',\n",
              " 'to',\n",
              " 'and',\n",
              " 'in',\n",
              " 'a',\n",
              " '\"',\n",
              " \"'s\",\n",
              " 'for',\n",
              " '-',\n",
              " 'that',\n",
              " 'on',\n",
              " 'is',\n",
              " 'was',\n",
              " 'said',\n",
              " 'with',\n",
              " 'he',\n",
              " 'as',\n",
              " 'it',\n",
              " 'by',\n",
              " 'at',\n",
              " '(',\n",
              " ')',\n",
              " 'from',\n",
              " 'his',\n",
              " \"''\",\n",
              " '``',\n",
              " 'an',\n",
              " 'be',\n",
              " 'has',\n",
              " 'are',\n",
              " 'have',\n",
              " 'but',\n",
              " 'were',\n",
              " 'not',\n",
              " 'this',\n",
              " 'who',\n",
              " 'they',\n",
              " 'had',\n",
              " 'i',\n",
              " 'which',\n",
              " 'will',\n",
              " 'their',\n",
              " ':',\n",
              " 'or',\n",
              " 'its',\n",
              " 'one',\n",
              " 'after',\n",
              " 'new',\n",
              " 'been',\n",
              " 'also',\n",
              " 'we',\n",
              " 'would',\n",
              " 'two',\n",
              " 'more',\n",
              " \"'\",\n",
              " 'first',\n",
              " 'about',\n",
              " 'up',\n",
              " 'when',\n",
              " 'year',\n",
              " 'there',\n",
              " 'all',\n",
              " '--',\n",
              " 'out',\n",
              " 'she',\n",
              " 'other',\n",
              " 'people',\n",
              " \"n't\",\n",
              " 'her',\n",
              " 'percent',\n",
              " 'than',\n",
              " 'over',\n",
              " 'into',\n",
              " 'last',\n",
              " 'some',\n",
              " 'government',\n",
              " 'time',\n",
              " '$',\n",
              " 'you',\n",
              " 'years',\n",
              " 'if',\n",
              " 'no',\n",
              " 'world',\n",
              " 'can',\n",
              " 'three',\n",
              " 'do',\n",
              " ';',\n",
              " 'president',\n",
              " 'only',\n",
              " 'state',\n",
              " 'million',\n",
              " 'could',\n",
              " 'us',\n",
              " 'most',\n",
              " '_',\n",
              " 'against',\n",
              " 'u.s.']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhv5q8EWP3G_",
        "outputId": "3caf7887-5d81-45c1-a404-d41cce0c1305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
              "        [ 0.0134,  0.2368, -0.1690,  ..., -0.5666,  0.0447,  0.3039],\n",
              "        [ 0.1516,  0.3018, -0.1676,  ..., -0.3565,  0.0164,  0.1022],\n",
              "        ...,\n",
              "        [ 0.1499,  0.7318,  0.4202,  ..., -0.1501, -0.4110,  0.3928],\n",
              "        [-0.6126, -0.8110, -0.1843,  ...,  0.0140,  0.1737, -0.6768],\n",
              "        [-0.2805, -0.0832,  1.0143,  ...,  0.8242, -0.7768,  0.6647]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.RNN**"
      ],
      "metadata": {
        "id": "7nfD52WBg7N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size, embedding_dim = embedding_matrix.num_embeddings, embedding_matrix.embedding_dim\n",
        "\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "model_1_3_rnn = SurnameClassifier3(nn.RNN, vocab_size, embedding_dim, hidden_size, output_size, vectors)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_3_rnn.parameters(), lr=0.008)"
      ],
      "metadata": {
        "id": "HD1jqDVpcDoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_3_rnn, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_3_rnn, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMi6Rs3BgeJj",
        "outputId": "64d877b5-5b82-4351-cb86-464de427993c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [157.5865], Train_acc: [0.2466], Test Loss: [41.0006], Test_acc: [0.2687]\n",
            "epoch [2]: Train Loss: [156.7572], Train_acc: [0.2588], Test Loss: [40.4519], Test_acc: [0.2687]\n",
            "epoch [3]: Train Loss: [156.8780], Train_acc: [0.2549], Test Loss: [41.1635], Test_acc: [0.1448]\n",
            "epoch [4]: Train Loss: [157.6601], Train_acc: [0.2580], Test Loss: [41.1777], Test_acc: [0.2687]\n",
            "epoch [5]: Train Loss: [156.9891], Train_acc: [0.2498], Test Loss: [40.2179], Test_acc: [0.2687]\n",
            "epoch [6]: Train Loss: [156.6522], Train_acc: [0.2559], Test Loss: [40.4560], Test_acc: [0.2687]\n",
            "epoch [7]: Train Loss: [155.8075], Train_acc: [0.2618], Test Loss: [40.4332], Test_acc: [0.2700]\n",
            "epoch [8]: Train Loss: [155.2566], Train_acc: [0.2813], Test Loss: [40.7423], Test_acc: [0.2687]\n",
            "epoch [9]: Train Loss: [157.3709], Train_acc: [0.2597], Test Loss: [40.5374], Test_acc: [0.2687]\n",
            "epoch [10]: Train Loss: [156.4842], Train_acc: [0.2554], Test Loss: [40.5132], Test_acc: [0.2687]\n",
            "epoch [11]: Train Loss: [157.8695], Train_acc: [0.2448], Test Loss: [41.2539], Test_acc: [0.2687]\n",
            "epoch [12]: Train Loss: [157.2946], Train_acc: [0.2544], Test Loss: [40.2499], Test_acc: [0.2687]\n",
            "epoch [13]: Train Loss: [157.3674], Train_acc: [0.2540], Test Loss: [41.1930], Test_acc: [0.2687]\n",
            "epoch [14]: Train Loss: [158.3706], Train_acc: [0.2475], Test Loss: [40.4110], Test_acc: [0.2687]\n",
            "epoch [15]: Train Loss: [157.1801], Train_acc: [0.2517], Test Loss: [40.6926], Test_acc: [0.2687]\n",
            "epoch [16]: Train Loss: [157.6505], Train_acc: [0.2525], Test Loss: [40.5823], Test_acc: [0.2687]\n",
            "epoch [17]: Train Loss: [157.7588], Train_acc: [0.2461], Test Loss: [41.8122], Test_acc: [0.1448]\n",
            "epoch [18]: Train Loss: [157.8498], Train_acc: [0.2539], Test Loss: [40.5111], Test_acc: [0.2687]\n",
            "epoch [19]: Train Loss: [156.7369], Train_acc: [0.2531], Test Loss: [40.6040], Test_acc: [0.1448]\n",
            "epoch [20]: Train Loss: [157.7006], Train_acc: [0.2540], Test Loss: [41.4133], Test_acc: [0.2140]\n",
            "epoch [21]: Train Loss: [156.9683], Train_acc: [0.2531], Test Loss: [41.1656], Test_acc: [0.2140]\n",
            "epoch [22]: Train Loss: [157.4676], Train_acc: [0.2432], Test Loss: [40.4057], Test_acc: [0.2687]\n",
            "epoch [23]: Train Loss: [157.5003], Train_acc: [0.2520], Test Loss: [41.3689], Test_acc: [0.2687]\n",
            "epoch [24]: Train Loss: [156.8007], Train_acc: [0.2589], Test Loss: [41.4776], Test_acc: [0.2687]\n",
            "epoch [25]: Train Loss: [156.9238], Train_acc: [0.2572], Test Loss: [40.9910], Test_acc: [0.2140]\n",
            "epoch [26]: Train Loss: [157.1089], Train_acc: [0.2495], Test Loss: [40.6877], Test_acc: [0.2687]\n",
            "epoch [27]: Train Loss: [156.9231], Train_acc: [0.2541], Test Loss: [40.3367], Test_acc: [0.2687]\n",
            "epoch [28]: Train Loss: [157.6640], Train_acc: [0.2501], Test Loss: [41.4926], Test_acc: [0.2140]\n",
            "epoch [29]: Train Loss: [157.1732], Train_acc: [0.2531], Test Loss: [40.5118], Test_acc: [0.2687]\n",
            "epoch [30]: Train Loss: [158.5180], Train_acc: [0.2475], Test Loss: [40.6459], Test_acc: [0.2687]\n",
            "CPU times: user 34.2 s, sys: 192 ms, total: 34.4 s\n",
            "Wall time: 34.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_3_rnn, input_surnames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkVqyaU0g4w1",
        "outputId": "3b7608c2-b9cd-491b-b770-ae7ca7fafd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: English, Вероятность: 27.0973%\n",
            "Страна: Arabic, Вероятность: 19.5020%\n",
            "Страна: Russian, Вероятность: 19.0715%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: English, Вероятность: 27.0973%\n",
            "Страна: Arabic, Вероятность: 19.5020%\n",
            "Страна: Russian, Вероятность: 19.0715%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.LSTM**"
      ],
      "metadata": {
        "id": "9irVYw5mhjEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size, embedding_dim = embedding_matrix.num_embeddings, embedding_matrix.embedding_dim\n",
        "\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "model_1_3_lstm = SurnameClassifier3(nn.LSTM, vocab_size, embedding_dim, hidden_size, output_size, vectors)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_3_lstm.parameters(), lr=0.008)"
      ],
      "metadata": {
        "id": "P3vIpsNdhmsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_3_lstm, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_3_lstm, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pli98j4qhmu4",
        "outputId": "39c7fc11-2191-442c-f85f-0c2e37c26651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [155.6605], Train_acc: [0.2622], Test Loss: [39.9990], Test_acc: [0.2687]\n",
            "epoch [2]: Train Loss: [154.0252], Train_acc: [0.2712], Test Loss: [39.9263], Test_acc: [0.2687]\n",
            "epoch [3]: Train Loss: [153.8765], Train_acc: [0.2712], Test Loss: [39.8668], Test_acc: [0.2687]\n",
            "epoch [4]: Train Loss: [153.7522], Train_acc: [0.2712], Test Loss: [39.9412], Test_acc: [0.2687]\n",
            "epoch [5]: Train Loss: [152.3537], Train_acc: [0.2895], Test Loss: [38.3266], Test_acc: [0.3420]\n",
            "epoch [6]: Train Loss: [141.7351], Train_acc: [0.3923], Test Loss: [36.0055], Test_acc: [0.4071]\n",
            "epoch [7]: Train Loss: [135.6088], Train_acc: [0.4214], Test Loss: [34.9978], Test_acc: [0.4176]\n",
            "epoch [8]: Train Loss: [127.0452], Train_acc: [0.4629], Test Loss: [31.4875], Test_acc: [0.5337]\n",
            "epoch [9]: Train Loss: [110.5685], Train_acc: [0.5639], Test Loss: [28.1971], Test_acc: [0.5861]\n",
            "epoch [10]: Train Loss: [99.3015], Train_acc: [0.6108], Test Loss: [26.0477], Test_acc: [0.6052]\n",
            "epoch [11]: Train Loss: [91.7067], Train_acc: [0.6374], Test Loss: [24.3073], Test_acc: [0.6325]\n",
            "epoch [12]: Train Loss: [83.3905], Train_acc: [0.6604], Test Loss: [22.9398], Test_acc: [0.6489]\n",
            "epoch [13]: Train Loss: [78.5312], Train_acc: [0.6705], Test Loss: [21.6521], Test_acc: [0.6580]\n",
            "epoch [14]: Train Loss: [71.2423], Train_acc: [0.6972], Test Loss: [21.1571], Test_acc: [0.6639]\n",
            "epoch [15]: Train Loss: [66.8140], Train_acc: [0.7136], Test Loss: [21.0120], Test_acc: [0.6821]\n",
            "epoch [16]: Train Loss: [62.7632], Train_acc: [0.7321], Test Loss: [19.7104], Test_acc: [0.7031]\n",
            "epoch [17]: Train Loss: [60.2464], Train_acc: [0.7378], Test Loss: [18.7269], Test_acc: [0.7086]\n",
            "epoch [18]: Train Loss: [56.0240], Train_acc: [0.7538], Test Loss: [19.0271], Test_acc: [0.7040]\n",
            "epoch [19]: Train Loss: [54.3792], Train_acc: [0.7622], Test Loss: [19.1715], Test_acc: [0.7168]\n",
            "epoch [20]: Train Loss: [50.8589], Train_acc: [0.7754], Test Loss: [20.3093], Test_acc: [0.6976]\n",
            "epoch [21]: Train Loss: [51.0425], Train_acc: [0.7749], Test Loss: [18.6431], Test_acc: [0.7163]\n",
            "epoch [22]: Train Loss: [46.1102], Train_acc: [0.7961], Test Loss: [18.6153], Test_acc: [0.7104]\n",
            "epoch [23]: Train Loss: [43.7822], Train_acc: [0.8051], Test Loss: [19.2546], Test_acc: [0.7204]\n",
            "epoch [24]: Train Loss: [42.3800], Train_acc: [0.8126], Test Loss: [19.5560], Test_acc: [0.7177]\n",
            "epoch [25]: Train Loss: [40.8829], Train_acc: [0.8153], Test Loss: [19.6336], Test_acc: [0.7122]\n",
            "epoch [26]: Train Loss: [38.4322], Train_acc: [0.8256], Test Loss: [20.4185], Test_acc: [0.7172]\n",
            "epoch [27]: Train Loss: [35.9794], Train_acc: [0.8358], Test Loss: [20.1862], Test_acc: [0.7222]\n",
            "epoch [28]: Train Loss: [35.4045], Train_acc: [0.8390], Test Loss: [21.8490], Test_acc: [0.7099]\n",
            "epoch [29]: Train Loss: [33.5154], Train_acc: [0.8482], Test Loss: [20.6496], Test_acc: [0.7195]\n",
            "epoch [30]: Train Loss: [31.2552], Train_acc: [0.8574], Test Loss: [21.7494], Test_acc: [0.7127]\n",
            "CPU times: user 1min 32s, sys: 351 ms, total: 1min 32s\n",
            "Wall time: 1min 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_3_lstm, input_surnames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVb8EB14hmx1",
        "outputId": "6149be26-217c-49ba-f46d-2f83c87179cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: Russian, Вероятность: 99.9159%\n",
            "Страна: Italian, Вероятность: 0.0459%\n",
            "Страна: Japanese, Вероятность: 0.0148%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: Russian, Вероятность: 99.9863%\n",
            "Страна: Czech, Вероятность: 0.0131%\n",
            "Страна: English, Вероятность: 0.0003%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_3_lstm.embedding.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOzHxhZDQuym",
        "outputId": "88d47e0d-7846-4bab-b05b-0531d3beed1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
              "        [ 0.0134,  0.2368, -0.1690,  ..., -0.5666,  0.0447,  0.3039],\n",
              "        [ 0.1516,  0.3018, -0.1676,  ..., -0.3565,  0.0164,  0.1022],\n",
              "        ...,\n",
              "        [ 0.1499,  0.7318,  0.4202,  ..., -0.1501, -0.4110,  0.3928],\n",
              "        [-0.6126, -0.8110, -0.1843,  ...,  0.0140,  0.1737, -0.6768],\n",
              "        [-0.2805, -0.0832,  1.0143,  ...,  0.8242, -0.7768,  0.6647]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.GRU**"
      ],
      "metadata": {
        "id": "3xnh3xrQiCnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size, embedding_dim = embedding_matrix.num_embeddings, embedding_matrix.embedding_dim\n",
        "\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "model_1_3_gru = SurnameClassifier3(nn.GRU, vocab_size, embedding_dim, hidden_size, output_size, vectors)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_3_gru.parameters(), lr=0.008)"
      ],
      "metadata": {
        "id": "Yqq1jbIGilFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_3_gru, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_3_gru, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZN7zVzbilIP",
        "outputId": "076919ea-eff5-4510-ab71-f3fcc21f9008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [142.0374], Train_acc: [0.3650], Test Loss: [30.5491], Test_acc: [0.5005]\n",
            "epoch [2]: Train Loss: [96.3893], Train_acc: [0.6036], Test Loss: [21.0465], Test_acc: [0.6630]\n",
            "epoch [3]: Train Loss: [69.5584], Train_acc: [0.7067], Test Loss: [18.1890], Test_acc: [0.7072]\n",
            "epoch [4]: Train Loss: [58.4745], Train_acc: [0.7489], Test Loss: [16.9398], Test_acc: [0.7259]\n",
            "epoch [5]: Train Loss: [50.1213], Train_acc: [0.7776], Test Loss: [16.9002], Test_acc: [0.7295]\n",
            "epoch [6]: Train Loss: [43.8177], Train_acc: [0.8004], Test Loss: [16.1358], Test_acc: [0.7445]\n",
            "epoch [7]: Train Loss: [38.7987], Train_acc: [0.8224], Test Loss: [16.3497], Test_acc: [0.7559]\n",
            "epoch [8]: Train Loss: [34.8221], Train_acc: [0.8426], Test Loss: [17.3167], Test_acc: [0.7523]\n",
            "epoch [9]: Train Loss: [30.7724], Train_acc: [0.8555], Test Loss: [16.9016], Test_acc: [0.7473]\n",
            "epoch [10]: Train Loss: [28.1542], Train_acc: [0.8666], Test Loss: [18.7019], Test_acc: [0.7291]\n",
            "epoch [11]: Train Loss: [26.5108], Train_acc: [0.8733], Test Loss: [18.0568], Test_acc: [0.7382]\n",
            "epoch [12]: Train Loss: [23.8356], Train_acc: [0.8814], Test Loss: [18.4920], Test_acc: [0.7395]\n",
            "epoch [13]: Train Loss: [23.4848], Train_acc: [0.8826], Test Loss: [18.9087], Test_acc: [0.7486]\n",
            "epoch [14]: Train Loss: [23.7457], Train_acc: [0.8821], Test Loss: [20.3221], Test_acc: [0.7391]\n",
            "epoch [15]: Train Loss: [24.3380], Train_acc: [0.8790], Test Loss: [20.5753], Test_acc: [0.7377]\n",
            "epoch [16]: Train Loss: [21.7245], Train_acc: [0.8914], Test Loss: [20.8924], Test_acc: [0.7413]\n",
            "epoch [17]: Train Loss: [20.8072], Train_acc: [0.8989], Test Loss: [21.3577], Test_acc: [0.7295]\n",
            "epoch [18]: Train Loss: [18.9244], Train_acc: [0.9062], Test Loss: [21.7583], Test_acc: [0.7313]\n",
            "epoch [19]: Train Loss: [18.3886], Train_acc: [0.9112], Test Loss: [22.4181], Test_acc: [0.7322]\n",
            "epoch [20]: Train Loss: [18.7134], Train_acc: [0.9057], Test Loss: [21.7027], Test_acc: [0.7327]\n",
            "epoch [21]: Train Loss: [19.7787], Train_acc: [0.9005], Test Loss: [22.5222], Test_acc: [0.7054]\n",
            "epoch [22]: Train Loss: [22.6669], Train_acc: [0.8838], Test Loss: [21.3849], Test_acc: [0.7382]\n",
            "epoch [23]: Train Loss: [18.9749], Train_acc: [0.9004], Test Loss: [22.3840], Test_acc: [0.7268]\n",
            "epoch [24]: Train Loss: [20.6074], Train_acc: [0.8958], Test Loss: [21.8993], Test_acc: [0.7240]\n",
            "epoch [25]: Train Loss: [20.7447], Train_acc: [0.8962], Test Loss: [23.2664], Test_acc: [0.7263]\n",
            "epoch [26]: Train Loss: [18.8328], Train_acc: [0.9062], Test Loss: [23.8220], Test_acc: [0.7199]\n",
            "epoch [27]: Train Loss: [19.4460], Train_acc: [0.9043], Test Loss: [23.8999], Test_acc: [0.7309]\n",
            "epoch [28]: Train Loss: [21.1935], Train_acc: [0.8924], Test Loss: [23.2750], Test_acc: [0.7400]\n",
            "epoch [29]: Train Loss: [21.1283], Train_acc: [0.8952], Test Loss: [23.2381], Test_acc: [0.7145]\n",
            "epoch [30]: Train Loss: [22.8368], Train_acc: [0.8835], Test Loss: [24.0405], Test_acc: [0.7113]\n",
            "CPU times: user 1min 14s, sys: 465 ms, total: 1min 14s\n",
            "Wall time: 1min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_3_gru, input_surnames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQcsDIxOilL8",
        "outputId": "16e4c977-4d0b-465c-dd6f-75b31c8c40e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: Russian, Вероятность: 99.9902%\n",
            "Страна: English, Вероятность: 0.0092%\n",
            "Страна: Czech, Вероятность: 0.0002%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: Russian, Вероятность: 97.0630%\n",
            "Страна: Czech, Вероятность: 2.5622%\n",
            "Страна: English, Вероятность: 0.2188%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**glove.6B.50d.txt**"
      ],
      "metadata": {
        "id": "GhdH4ryCi7cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/glove.6B.50d.txt'\n",
        "\n",
        "word_vectors = {}\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        parts = line.split()\n",
        "        word = parts[0]\n",
        "        vector = [float(val) for val in parts[1:]]\n",
        "        word_vectors[word] = vector\n",
        "\n",
        "words = list(word_vectors.keys())\n",
        "vectors = torch.FloatTensor(list(word_vectors.values()))\n",
        "embedding_matrix = nn.Embedding.from_pretrained(vectors, freeze=True)"
      ],
      "metadata": {
        "id": "EqWmcCFBjcJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJYFdT37jkJ1",
        "outputId": "a2022acd-a3cd-4800-bd18-b88eba842daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(400000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDfrzgwlRnYA",
        "outputId": "5a93e374-c239-47a5-9ac3-8e4d4f96a20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
              "        [ 0.0134,  0.2368, -0.1690,  ..., -0.5666,  0.0447,  0.3039],\n",
              "        [ 0.1516,  0.3018, -0.1676,  ..., -0.3565,  0.0164,  0.1022],\n",
              "        ...,\n",
              "        [-0.5118,  0.0587,  1.0913,  ..., -0.2500, -1.1250,  1.5863],\n",
              "        [-0.7590, -0.4743,  0.4737,  ...,  0.7895, -0.0141,  0.6448],\n",
              "        [ 0.0726, -0.5139,  0.4728,  ..., -0.1891, -0.5902,  0.5556]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.RNN**"
      ],
      "metadata": {
        "id": "zksl6hDVjxM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size, embedding_dim = embedding_matrix.num_embeddings, embedding_matrix.embedding_dim\n",
        "\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "model_1_3_rnn = SurnameClassifier3(nn.RNN, vocab_size, embedding_dim, hidden_size, output_size, vectors)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_3_rnn.parameters(), lr=0.008)"
      ],
      "metadata": {
        "id": "YlRu4JmwjzEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_3_rnn, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_3_rnn, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzq10y89jzHq",
        "outputId": "afffd6d0-5e5a-46a9-ff67-52c5c96fa529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [158.7632], Train_acc: [0.2460], Test Loss: [40.7909], Test_acc: [0.2687]\n",
            "epoch [2]: Train Loss: [157.2390], Train_acc: [0.2491], Test Loss: [40.8029], Test_acc: [0.2687]\n",
            "epoch [3]: Train Loss: [157.0077], Train_acc: [0.2523], Test Loss: [40.7771], Test_acc: [0.2687]\n",
            "epoch [4]: Train Loss: [156.2178], Train_acc: [0.2633], Test Loss: [40.2426], Test_acc: [0.2140]\n",
            "epoch [5]: Train Loss: [156.2795], Train_acc: [0.2609], Test Loss: [41.0542], Test_acc: [0.2687]\n",
            "epoch [6]: Train Loss: [157.4924], Train_acc: [0.2530], Test Loss: [40.4707], Test_acc: [0.2687]\n",
            "epoch [7]: Train Loss: [158.3839], Train_acc: [0.2363], Test Loss: [40.2675], Test_acc: [0.2687]\n",
            "epoch [8]: Train Loss: [157.9359], Train_acc: [0.2561], Test Loss: [40.6484], Test_acc: [0.2687]\n",
            "epoch [9]: Train Loss: [156.5750], Train_acc: [0.2502], Test Loss: [40.5376], Test_acc: [0.2687]\n",
            "epoch [10]: Train Loss: [157.3250], Train_acc: [0.2719], Test Loss: [40.5645], Test_acc: [0.2140]\n",
            "epoch [11]: Train Loss: [157.5938], Train_acc: [0.2492], Test Loss: [40.8708], Test_acc: [0.2687]\n",
            "epoch [12]: Train Loss: [157.5294], Train_acc: [0.2628], Test Loss: [40.7770], Test_acc: [0.2140]\n",
            "epoch [13]: Train Loss: [156.8658], Train_acc: [0.2557], Test Loss: [40.9909], Test_acc: [0.2687]\n",
            "epoch [14]: Train Loss: [158.0723], Train_acc: [0.2466], Test Loss: [42.0438], Test_acc: [0.1448]\n",
            "epoch [15]: Train Loss: [157.2292], Train_acc: [0.2473], Test Loss: [41.4854], Test_acc: [0.2687]\n",
            "epoch [16]: Train Loss: [157.6232], Train_acc: [0.2464], Test Loss: [40.4015], Test_acc: [0.2687]\n",
            "epoch [17]: Train Loss: [156.6705], Train_acc: [0.2602], Test Loss: [40.7741], Test_acc: [0.2687]\n",
            "epoch [18]: Train Loss: [156.6416], Train_acc: [0.2533], Test Loss: [40.6535], Test_acc: [0.2687]\n",
            "epoch [19]: Train Loss: [157.5320], Train_acc: [0.2564], Test Loss: [40.1892], Test_acc: [0.2687]\n",
            "epoch [20]: Train Loss: [156.3566], Train_acc: [0.2548], Test Loss: [41.2473], Test_acc: [0.2687]\n",
            "epoch [21]: Train Loss: [157.5354], Train_acc: [0.2421], Test Loss: [41.0375], Test_acc: [0.2687]\n",
            "epoch [22]: Train Loss: [156.5974], Train_acc: [0.2597], Test Loss: [40.3618], Test_acc: [0.2687]\n",
            "epoch [23]: Train Loss: [157.3420], Train_acc: [0.2426], Test Loss: [42.9448], Test_acc: [0.2687]\n",
            "epoch [24]: Train Loss: [157.6339], Train_acc: [0.2523], Test Loss: [40.6996], Test_acc: [0.2687]\n",
            "epoch [25]: Train Loss: [157.1846], Train_acc: [0.2542], Test Loss: [40.6816], Test_acc: [0.2687]\n",
            "epoch [26]: Train Loss: [157.3316], Train_acc: [0.2574], Test Loss: [41.4219], Test_acc: [0.2687]\n",
            "epoch [27]: Train Loss: [157.3121], Train_acc: [0.2582], Test Loss: [40.6506], Test_acc: [0.2687]\n",
            "epoch [28]: Train Loss: [157.6109], Train_acc: [0.2522], Test Loss: [41.7229], Test_acc: [0.2140]\n",
            "epoch [29]: Train Loss: [157.4716], Train_acc: [0.2575], Test Loss: [40.5535], Test_acc: [0.2687]\n",
            "epoch [30]: Train Loss: [157.3547], Train_acc: [0.2547], Test Loss: [40.7531], Test_acc: [0.2687]\n",
            "CPU times: user 43.2 s, sys: 198 ms, total: 43.4 s\n",
            "Wall time: 44.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_3_rnn, input_surnames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cja8naEjzMJ",
        "outputId": "de033ee2-bf7a-4351-8329-32b6f764985f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: English, Вероятность: 31.2288%\n",
            "Страна: Russian, Вероятность: 23.9761%\n",
            "Страна: Arabic, Вероятность: 17.3108%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: English, Вероятность: 31.2288%\n",
            "Страна: Russian, Вероятность: 23.9761%\n",
            "Страна: Arabic, Вероятность: 17.3108%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_3_rnn.embedding.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C10nhMz6Rywm",
        "outputId": "eb71dde3-0d02-41a7-e4bb-742783156b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.4180,  0.2497, -0.4124,  ..., -0.1841, -0.1151, -0.7858],\n",
              "        [ 0.0134,  0.2368, -0.1690,  ..., -0.5666,  0.0447,  0.3039],\n",
              "        [ 0.1516,  0.3018, -0.1676,  ..., -0.3565,  0.0164,  0.1022],\n",
              "        ...,\n",
              "        [-0.5118,  0.0587,  1.0913,  ..., -0.2500, -1.1250,  1.5863],\n",
              "        [-0.7590, -0.4743,  0.4737,  ...,  0.7895, -0.0141,  0.6448],\n",
              "        [ 0.0726, -0.5139,  0.4728,  ..., -0.1891, -0.5902,  0.5556]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.LSTM**"
      ],
      "metadata": {
        "id": "XFDbB981jziW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size, embedding_dim = embedding_matrix.num_embeddings, embedding_matrix.embedding_dim\n",
        "\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "model_1_3_lstm = SurnameClassifier3(nn.LSTM, vocab_size, embedding_dim, hidden_size, output_size, vectors)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_3_lstm.parameters(), lr=0.008)"
      ],
      "metadata": {
        "id": "dbPYPd-Sj1yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_3_lstm, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_3_lstm, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej0BAFhej12f",
        "outputId": "fbd57bf4-8d4e-4fb9-c431-a65488734b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [155.3275], Train_acc: [0.2614], Test Loss: [39.9735], Test_acc: [0.2687]\n",
            "epoch [2]: Train Loss: [154.0306], Train_acc: [0.2689], Test Loss: [40.0078], Test_acc: [0.2687]\n",
            "epoch [3]: Train Loss: [153.9457], Train_acc: [0.2712], Test Loss: [39.9305], Test_acc: [0.2687]\n",
            "epoch [4]: Train Loss: [153.7668], Train_acc: [0.2637], Test Loss: [39.9362], Test_acc: [0.2687]\n",
            "epoch [5]: Train Loss: [153.7169], Train_acc: [0.2712], Test Loss: [39.8777], Test_acc: [0.2687]\n",
            "epoch [6]: Train Loss: [153.7227], Train_acc: [0.2642], Test Loss: [39.9645], Test_acc: [0.2687]\n",
            "epoch [7]: Train Loss: [153.7850], Train_acc: [0.2712], Test Loss: [39.7929], Test_acc: [0.2687]\n",
            "epoch [8]: Train Loss: [153.5053], Train_acc: [0.2712], Test Loss: [39.8856], Test_acc: [0.2687]\n",
            "epoch [9]: Train Loss: [153.5648], Train_acc: [0.2712], Test Loss: [39.9457], Test_acc: [0.2687]\n",
            "epoch [10]: Train Loss: [153.5539], Train_acc: [0.2712], Test Loss: [39.8434], Test_acc: [0.2687]\n",
            "epoch [11]: Train Loss: [153.5320], Train_acc: [0.2712], Test Loss: [39.8998], Test_acc: [0.2687]\n",
            "epoch [12]: Train Loss: [153.5038], Train_acc: [0.2712], Test Loss: [39.8283], Test_acc: [0.2687]\n",
            "epoch [13]: Train Loss: [153.5042], Train_acc: [0.2712], Test Loss: [39.8524], Test_acc: [0.2687]\n",
            "epoch [14]: Train Loss: [153.4386], Train_acc: [0.2662], Test Loss: [39.8609], Test_acc: [0.2687]\n",
            "epoch [15]: Train Loss: [153.4897], Train_acc: [0.2712], Test Loss: [39.7956], Test_acc: [0.2687]\n",
            "epoch [16]: Train Loss: [153.4332], Train_acc: [0.2712], Test Loss: [39.8537], Test_acc: [0.2687]\n",
            "epoch [17]: Train Loss: [152.7246], Train_acc: [0.2712], Test Loss: [38.9345], Test_acc: [0.2687]\n",
            "epoch [18]: Train Loss: [142.7004], Train_acc: [0.3116], Test Loss: [35.3314], Test_acc: [0.3543]\n",
            "epoch [19]: Train Loss: [125.1486], Train_acc: [0.4583], Test Loss: [29.7272], Test_acc: [0.5383]\n",
            "epoch [20]: Train Loss: [99.8272], Train_acc: [0.5929], Test Loss: [24.0253], Test_acc: [0.6334]\n",
            "epoch [21]: Train Loss: [85.7192], Train_acc: [0.6487], Test Loss: [22.0981], Test_acc: [0.6521]\n",
            "epoch [22]: Train Loss: [77.0399], Train_acc: [0.6759], Test Loss: [21.2793], Test_acc: [0.6617]\n",
            "epoch [23]: Train Loss: [70.8211], Train_acc: [0.7039], Test Loss: [20.0940], Test_acc: [0.6817]\n",
            "epoch [24]: Train Loss: [65.8928], Train_acc: [0.7202], Test Loss: [19.3142], Test_acc: [0.6922]\n",
            "epoch [25]: Train Loss: [62.4262], Train_acc: [0.7317], Test Loss: [18.9585], Test_acc: [0.7154]\n",
            "epoch [26]: Train Loss: [57.8133], Train_acc: [0.7513], Test Loss: [18.5301], Test_acc: [0.7154]\n",
            "epoch [27]: Train Loss: [54.5751], Train_acc: [0.7626], Test Loss: [19.7293], Test_acc: [0.7127]\n",
            "epoch [28]: Train Loss: [52.3450], Train_acc: [0.7728], Test Loss: [18.9440], Test_acc: [0.7086]\n",
            "epoch [29]: Train Loss: [49.1795], Train_acc: [0.7813], Test Loss: [18.2256], Test_acc: [0.7254]\n",
            "epoch [30]: Train Loss: [46.0372], Train_acc: [0.7962], Test Loss: [18.5489], Test_acc: [0.7136]\n",
            "CPU times: user 1min 32s, sys: 303 ms, total: 1min 32s\n",
            "Wall time: 1min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_3_lstm, input_surnames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bifyEVT3j16s",
        "outputId": "aa6495bc-3892-462b-cfdd-4ff5fa4cda10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: Russian, Вероятность: 99.8016%\n",
            "Страна: Polish, Вероятность: 0.0521%\n",
            "Страна: Czech, Вероятность: 0.0481%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: Russian, Вероятность: 96.8486%\n",
            "Страна: Czech, Вероятность: 1.6179%\n",
            "Страна: English, Вероятность: 0.7476%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nn.GRU**"
      ],
      "metadata": {
        "id": "9FpO8WDOj2K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size, embedding_dim = embedding_matrix.num_embeddings, embedding_matrix.embedding_dim\n",
        "\n",
        "hidden_size = 128\n",
        "output_size = len(nationality_to_idx)\n",
        "model_1_3_gru = SurnameClassifier3(nn.GRU, vocab_size, embedding_dim, hidden_size, output_size, vectors)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_1_3_gru.parameters(), lr=0.008)"
      ],
      "metadata": {
        "id": "3U0ELjCcj4Dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "losses_train, losses_test = [], []\n",
        "for epoch in range(30):\n",
        "    total_loss_train, train_accuracy = train(model_1_3_gru, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_1_3_gru, test_loader)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujXI_3isj4HO",
        "outputId": "bd150393-32b7-47e8-ba64-1d63fd418c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [138.9185], Train_acc: [0.3856], Test Loss: [30.9273], Test_acc: [0.5027]\n",
            "epoch [2]: Train Loss: [95.9503], Train_acc: [0.6006], Test Loss: [21.9414], Test_acc: [0.6571]\n",
            "epoch [3]: Train Loss: [70.7707], Train_acc: [0.7075], Test Loss: [18.0926], Test_acc: [0.7117]\n",
            "epoch [4]: Train Loss: [58.6510], Train_acc: [0.7474], Test Loss: [16.8484], Test_acc: [0.7254]\n",
            "epoch [5]: Train Loss: [50.8670], Train_acc: [0.7771], Test Loss: [15.9615], Test_acc: [0.7354]\n",
            "epoch [6]: Train Loss: [43.7036], Train_acc: [0.8045], Test Loss: [16.7434], Test_acc: [0.7259]\n",
            "epoch [7]: Train Loss: [38.5307], Train_acc: [0.8230], Test Loss: [16.4002], Test_acc: [0.7532]\n",
            "epoch [8]: Train Loss: [33.7461], Train_acc: [0.8490], Test Loss: [17.2785], Test_acc: [0.7423]\n",
            "epoch [9]: Train Loss: [29.9178], Train_acc: [0.8582], Test Loss: [17.5472], Test_acc: [0.7368]\n",
            "epoch [10]: Train Loss: [26.2582], Train_acc: [0.8763], Test Loss: [17.5898], Test_acc: [0.7263]\n",
            "epoch [11]: Train Loss: [24.5920], Train_acc: [0.8841], Test Loss: [18.3202], Test_acc: [0.7427]\n",
            "epoch [12]: Train Loss: [23.5618], Train_acc: [0.8868], Test Loss: [18.9311], Test_acc: [0.7322]\n",
            "epoch [13]: Train Loss: [21.9406], Train_acc: [0.8942], Test Loss: [19.4916], Test_acc: [0.7341]\n",
            "epoch [14]: Train Loss: [21.1042], Train_acc: [0.8996], Test Loss: [19.3944], Test_acc: [0.7363]\n",
            "epoch [15]: Train Loss: [20.3534], Train_acc: [0.9021], Test Loss: [21.4712], Test_acc: [0.7222]\n",
            "epoch [16]: Train Loss: [21.2399], Train_acc: [0.8934], Test Loss: [20.8453], Test_acc: [0.7268]\n",
            "epoch [17]: Train Loss: [20.2914], Train_acc: [0.9024], Test Loss: [20.8190], Test_acc: [0.7309]\n",
            "epoch [18]: Train Loss: [20.3501], Train_acc: [0.9013], Test Loss: [21.6821], Test_acc: [0.7318]\n",
            "epoch [19]: Train Loss: [20.2522], Train_acc: [0.8988], Test Loss: [22.2184], Test_acc: [0.7332]\n",
            "epoch [20]: Train Loss: [18.7318], Train_acc: [0.9095], Test Loss: [21.1160], Test_acc: [0.7382]\n",
            "epoch [21]: Train Loss: [18.7104], Train_acc: [0.9045], Test Loss: [21.6805], Test_acc: [0.7409]\n",
            "epoch [22]: Train Loss: [20.4979], Train_acc: [0.8952], Test Loss: [20.8268], Test_acc: [0.7309]\n",
            "epoch [23]: Train Loss: [23.5816], Train_acc: [0.8849], Test Loss: [22.0640], Test_acc: [0.7268]\n",
            "epoch [24]: Train Loss: [22.9370], Train_acc: [0.8855], Test Loss: [21.9884], Test_acc: [0.7250]\n",
            "epoch [25]: Train Loss: [20.6281], Train_acc: [0.8973], Test Loss: [21.5865], Test_acc: [0.7318]\n",
            "epoch [26]: Train Loss: [21.1180], Train_acc: [0.8953], Test Loss: [22.3050], Test_acc: [0.7204]\n",
            "epoch [27]: Train Loss: [21.6707], Train_acc: [0.8928], Test Loss: [22.0078], Test_acc: [0.7086]\n",
            "epoch [28]: Train Loss: [19.3076], Train_acc: [0.9003], Test Loss: [22.6767], Test_acc: [0.7263]\n",
            "epoch [29]: Train Loss: [18.3913], Train_acc: [0.9047], Test Loss: [22.8358], Test_acc: [0.7350]\n",
            "epoch [30]: Train Loss: [19.6010], Train_acc: [0.9044], Test Loss: [24.3547], Test_acc: [0.7199]\n",
            "CPU times: user 1min 13s, sys: 665 ms, total: 1min 14s\n",
            "Wall time: 1min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_surnames = [\"paramonov\", \"perov\"]\n",
        "predict(model_1_3_gru, input_surnames)"
      ],
      "metadata": {
        "id": "JP_6Aewjj4Kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7831a521-57b5-47ed-a7e9-e3b9f6531a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фамилия: paramonov\n",
            "Страна: Russian, Вероятность: 99.2991%\n",
            "Страна: Czech, Вероятность: 0.6805%\n",
            "Страна: Dutch, Вероятность: 0.0102%\n",
            "\n",
            "Фамилия: perov\n",
            "Страна: Russian, Вероятность: 99.8437%\n",
            "Страна: English, Вероятность: 0.1247%\n",
            "Страна: Czech, Вероятность: 0.0299%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7kf990U9Do-"
      },
      "source": [
        "## 2. Классификация обзоров на фильмы (RNN)\n",
        "\n",
        "Датасет: https://disk.yandex.ru/d/tdinpb0nN_Dsrg\n",
        "\n",
        "2.1 Создайте набор данных на основе файлов polarity/positive_reviews.csv (положительные отзывы) и polarity/negative_reviews.csv (отрицательные отзывы). Разбейте на обучающую и тестовую выборку.\n",
        "  * токен = __слово__\n",
        "  * данные для обучения в датасете представляются в виде последовательности индексов токенов\n",
        "  * словарь создается на основе _только_ обучающей выборки. Для корректной обработки ситуаций, когда в тестовой выборке встретится токен, который не хранится в словаре, добавьте в словарь специальный токен `<UNK>`\n",
        "  * добавьте предобработку текста\n",
        "\n",
        "2.2. Обучите классификатор.\n",
        "  \n",
        "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding`\n",
        "    - подберите адекватную размерность вектора эмбеддинга:\n",
        "    - модуль `nn.Embedding` обучается\n",
        "\n",
        "  * Используйте рекуррентные слои (`nn.RNN`, `nn.LSTM`, `nn.GRU`)\n",
        "\n",
        "\n",
        "2.3 Измерить точность на тестовой выборке. Проверить работоспособность модели: придумать небольшой отзыв, прогнать его через модель и вывести номер предсказанного класса (сделать это для явно позитивного и явно негативного отзыва)\n",
        "* Целевое значение accuracy на валидации - 70+%"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/positive_reviews.txt\", sep='%-%', header=None, engine=\"python\")\n",
        "positive[\"type\"] = \"positive\"\n",
        "\n",
        "negative = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/negative_reviews.txt\", sep='%-%', header=None, engine=\"python\")\n",
        "negative[\"type\"] = \"negative\"\n",
        "\n",
        "df_review = pd.concat([positive, negative], ignore_index=True)\n",
        "\n",
        "df_review.columns = [\"review\", \"type\"]"
      ],
      "metadata": {
        "id": "oyqQWYF1pO1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_review['type'] = df_review['type'].replace({'positive': 1, 'negative': 0})"
      ],
      "metadata": {
        "id": "YJQbamsepO4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "EoibhHwJpO59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef5dcf0-3d01-4ca4-c67e-4660ae4860dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z]', ' ', text)\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    processed_text = ' '.join(tokens)\n",
        "\n",
        "    return processed_text\n",
        "\n",
        "df_review['review'] = df_review['review'].apply(preprocess_text)\n",
        "\n",
        "df_review.head()"
      ],
      "metadata": {
        "id": "1i0kfQ_QpO8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "293e898d-5779-49b0-854e-98ea6f57254e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  type\n",
              "0                       simplistic silly and tedious     1\n",
              "1  it s so laddish and juvenile only teenage boy ...     1\n",
              "2  exploitative and largely devoid of the depth o...     1\n",
              "3  garbus discard the potential for pathological ...     1\n",
              "4  a visually flashy but narratively opaque and e...     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b20c8d74-9e97-46e0-907d-43ccec6f41d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>simplistic silly and tedious</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it s so laddish and juvenile only teenage boy ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>exploitative and largely devoid of the depth o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>garbus discard the potential for pathological ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a visually flashy but narratively opaque and e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b20c8d74-9e97-46e0-907d-43ccec6f41d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b20c8d74-9e97-46e0-907d-43ccec6f41d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b20c8d74-9e97-46e0-907d-43ccec6f41d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b8b0d02-57e2-4edb-a118-5b9f864e2033\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b8b0d02-57e2-4edb-a118-5b9f864e2033')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b8b0d02-57e2-4edb-a118-5b9f864e2033 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, data):\n",
        "        self.idx_to_token, self.token_to_idx = self.build_vocab(data)\n",
        "        self.vocab_len = len(self.idx_to_token)\n",
        "        self.max_seq_len = self.calculate_max_seq_len(data)\n",
        "\n",
        "    def build_vocab(self, data):\n",
        "        tokens = set()\n",
        "        tokens.add('<PAD>')\n",
        "        tokens.add('<UNK>')\n",
        "\n",
        "        for review in data:\n",
        "            review_tokens = word_tokenize(review.lower())\n",
        "            tokens.update(review_tokens)\n",
        "\n",
        "        idx_to_token = {idx: token for idx, token in enumerate(tokens, start=0)}\n",
        "        token_to_idx = {token: idx for idx, token in enumerate(tokens, start=0)}\n",
        "\n",
        "        return idx_to_token, token_to_idx\n",
        "\n",
        "    def calculate_max_seq_len(self, data):\n",
        "        return max(len(word_tokenize(review.lower())) for review in data)"
      ],
      "metadata": {
        "id": "_ihkJ87_pO-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, X, y, vocab: Vocab):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def vectorize(self, review):\n",
        "        review = review.split()\n",
        "        indices = [self.vocab.token_to_idx.get(word, self.vocab.token_to_idx['<UNK>']) for word in review]\n",
        "\n",
        "\n",
        "        while len(indices) < self.vocab.max_seq_len:\n",
        "            indices.append(self.vocab.token_to_idx['<PAD>'])\n",
        "\n",
        "        return indices[:self.vocab.max_seq_len]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        review = self.X.iloc[idx]\n",
        "        target = self.y.iloc[idx]\n",
        "\n",
        "        vectorized_review = self.vectorize(review)\n",
        "\n",
        "        return {'review': torch.tensor(vectorized_review,  dtype=torch.long), 'target':torch.tensor(target, dtype=torch.long)}"
      ],
      "metadata": {
        "id": "0UxMTi2XpPA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df_review, test_size=0.2, random_state=42)\n",
        "\n",
        "vocab = Vocab(df_review['review'])\n",
        "\n",
        "train_dataset = ReviewDataset(X=train_df['review'], y=train_df['type'], vocab=vocab)\n",
        "test_dataset = ReviewDataset(X=test_df['review'], y=test_df['type'], vocab=vocab)"
      ],
      "metadata": {
        "id": "pYaWuiaLpPC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(review):\n",
        "        review = preprocess_text(review)\n",
        "        review = review.split()\n",
        "        indices = [vocab.token_to_idx.get(word, vocab.token_to_idx['<UNK>']) for word in review]\n",
        "\n",
        "        while len(indices) < vocab.max_seq_len:\n",
        "            indices.append(vocab.token_to_idx['<PAD>'])\n",
        "\n",
        "        return indices[:vocab.max_seq_len]"
      ],
      "metadata": {
        "id": "IxmQoIQZpPFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, max_seq_len, num_layers=2, freeze_embedding=True, dropout_rate=0.5):\n",
        "        super(ReviewClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight.requires_grad = freeze_embedding\n",
        "\n",
        "        self.rnn_lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.rnn_gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        lstm_out, _ = self.rnn_lstm(x.clone())\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "\n",
        "        gru_out, _ = self.rnn_gru(x.clone())\n",
        "        gru_out = gru_out[:, -1, :]\n",
        "\n",
        "        # Объединение выходов\n",
        "        combined_out = torch.cat([lstm_out, gru_out], dim=1)\n",
        "\n",
        "        combined_out = self.relu(combined_out)\n",
        "        combined_out = self.dropout(combined_out)\n",
        "\n",
        "        output = self.relu(self.fc1(combined_out))\n",
        "        output = self.fc2(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "IPjIRcpBpPG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "vocab_size = vocab.vocab_len\n",
        "max_seq_len = vocab.max_seq_len\n",
        "embedding_dim = 150\n",
        "hidden_size = 128\n",
        "output_size = 2\n",
        "\n",
        "model_3_1 = ReviewClassifier(vocab_size, embedding_dim, hidden_size, output_size, max_seq_len, freeze_embedding=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_3_1.parameters(), lr=0.002)"
      ],
      "metadata": {
        "id": "-uWT_28jpPI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dl, optimizer, criterion):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0.0\n",
        "    correct_samples = 0.0\n",
        "\n",
        "    for batch in train_dl:\n",
        "        inputs, targets = batch['review'], batch['target']\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets.squeeze())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss\n",
        "\n",
        "        total_samples += targets.shape[0]\n",
        "\n",
        "        _, prediction_indices = torch.max(outputs, 1)\n",
        "        correct_samples += torch.sum(prediction_indices==targets)\n",
        "\n",
        "    train_accuracy = float(correct_samples) / total_samples\n",
        "\n",
        "    return total_loss, train_accuracy\n",
        "\n",
        "def test(model, test_dl, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0.0\n",
        "    correct_samples = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch in test_dl:\n",
        "\n",
        "          inputs, targets = batch['review'], batch['target']\n",
        "          inp = inputs\n",
        "\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, targets.squeeze())\n",
        "          total_loss += loss\n",
        "\n",
        "\n",
        "          total_samples += targets.shape[0]\n",
        "          _, predictions_indices = torch.max(outputs, 1)\n",
        "          correct_samples += torch.sum(predictions_indices==targets)\n",
        "\n",
        "    test_accuracy = correct_samples / total_samples\n",
        "\n",
        "    return total_loss, test_accuracy"
      ],
      "metadata": {
        "id": "xq9JV8iCpPMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model_3_1.parameters())\n",
        "print(f\"Total parameters: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8AC8OP2ZFcC",
        "outputId": "a2d891a6-d085-4d72-e06e-d08842de1fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 2982852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses_train, losses_test = [], []\n",
        "for epoch in range(10):\n",
        "    total_loss_train, train_accuracy = train(model_3_1, train_loader, optimizer, criterion)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    total_loss_test, test_accuracy = test(model_3_1, test_loader, criterion)\n",
        "    losses_test.append(total_loss_test.item())\n",
        "\n",
        "    print(f\"epoch [{epoch+1}]: Train Loss: [{total_loss_train:.4f}], Train_acc: [{train_accuracy:.4f}],\"\n",
        "                            f\" Test Loss: [{total_loss_test:.4f}], Test_acc: [{test_accuracy:.4f}]\")\n",
        "\n",
        "    if test_accuracy > 0.7:\n",
        "        break"
      ],
      "metadata": {
        "id": "LBNP5mQNq1YP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e858993-9c34-4ea2-b20f-69e9c486fb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch [1]: Train Loss: [46.5835], Train_acc: [0.4988], Test Loss: [11.7845], Test_acc: [0.5021]\n",
            "epoch [2]: Train Loss: [46.4640], Train_acc: [0.5008], Test Loss: [11.7012], Test_acc: [0.5963]\n",
            "epoch [3]: Train Loss: [44.3054], Train_acc: [0.6165], Test Loss: [10.5756], Test_acc: [0.6507]\n",
            "epoch [4]: Train Loss: [35.0559], Train_acc: [0.7595], Test Loss: [9.6578], Test_acc: [0.7117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(review):\n",
        "        review = preprocess_text(review)\n",
        "        print(review)\n",
        "        indices = [vocab.token_to_idx.get(word, vocab.token_to_idx['<UNK>']) for word in review]\n",
        "\n",
        "        while len(indices) < vocab.max_seq_len:\n",
        "            indices.append(vocab.token_to_idx['<PAD>'])\n",
        "\n",
        "        return torch.tensor(indices[:vocab.max_seq_len], dtype=torch.long)\n",
        "\n",
        "reviews = [\n",
        "    \"This movie exceeded all my expectations! The acting was brilliant, and the storyline kept me engaged from start to finish. A must-watch!\",\n",
        "    \"An absolute masterpiece! The director's vision and the performances by the cast were outstanding. I was captivated throughout the entire film.\",\n",
        "    \"I can't express how much I enjoyed this movie. The plot twists were unexpected, and the cinematography was stunning. Highly recommended!\",\n",
        "\n",
        "    \"This film was a huge letdown. The plot was predictable, the characters were one-dimensional, and the acting was subpar. I regret spending my time and money on it.\",\n",
        "    \"I wouldn't recommend this movie. The marketing promised an exciting adventure, but it turned out to be a dull story. The special effects were mediocre, and the dialogue was tasteless\",\n",
        "]\n",
        "\n",
        "for input_review in reviews:\n",
        "    vec_input_review = vectorize(input_review)\n",
        "    input_tensor = vec_input_review.view(1, -1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model_3_1.eval()\n",
        "        outputs = model_3_1(input_tensor)\n",
        "        _, predictions_indices = torch.max(outputs, 1)\n",
        "\n",
        "    print(f'Отзыв: {input_review} \\nКласс: {predictions_indices.item()}')"
      ],
      "metadata": {
        "id": "2HcCYlVes4zW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180bfab4-be97-4611-938f-725628f2b6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this movie exceeded all my expectation the acting wa brilliant and the storyline kept me engaged from start to finish a must watch\n",
            "Отзыв: This movie exceeded all my expectations! The acting was brilliant, and the storyline kept me engaged from start to finish. A must-watch! \n",
            "Класс: 1\n",
            "an absolute masterpiece the director s vision and the performance by the cast were outstanding i wa captivated throughout the entire film\n",
            "Отзыв: An absolute masterpiece! The director's vision and the performances by the cast were outstanding. I was captivated throughout the entire film. \n",
            "Класс: 1\n",
            "i can t express how much i enjoyed this movie the plot twist were unexpected and the cinematography wa stunning highly recommended\n",
            "Отзыв: I can't express how much I enjoyed this movie. The plot twists were unexpected, and the cinematography was stunning. Highly recommended! \n",
            "Класс: 1\n",
            "this film wa a huge letdown the plot wa predictable the character were one dimensional and the acting wa subpar i regret spending my time and money on it\n",
            "Отзыв: This film was a huge letdown. The plot was predictable, the characters were one-dimensional, and the acting was subpar. I regret spending my time and money on it. \n",
            "Класс: 1\n",
            "i wouldn t recommend this movie the marketing promised an exciting adventure but it turned out to be a dull story the special effect were mediocre and the dialogue wa tasteless\n",
            "Отзыв: I wouldn't recommend this movie. The marketing promised an exciting adventure, but it turned out to be a dull story. The special effects were mediocre, and the dialogue was tasteless \n",
            "Класс: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nfwg9b3_tSdS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}