{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKMq7dp2W15Y",
        "outputId": "8d2d1184-4ff3-497c-841b-766dd2b9f4c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "5\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBkqaK5bawXN",
        "outputId": "b02f8e15-507f-4234-d252-fd5810516f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmWCBWxrBUB3"
      },
      "source": [
        "## 1. Генерирование русских имен при помощи RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "990obDBwCC7V"
      },
      "source": [
        "Датасет: https://disk.yandex.ru/i/2yt18jHUgVEoIw\n",
        "\n",
        "1.1 На основе файла name_rus.txt создайте датасет.\n",
        "  * Учтите, что имена могут иметь различную длину\n",
        "  * Добавьте 4 специальных токена:\n",
        "    * `<PAD>` для дополнения последовательности до нужной длины;\n",
        "    * `<UNK>` для корректной обработки ранее не встречавшихся токенов;\n",
        "    * `<SOS>` для обозначения начала последовательности;\n",
        "    * `<EOS>` для обозначения конца последовательности.\n",
        "  * Преобразовывайте строку в последовательность индексов с учетом следующих замечаний:\n",
        "    * в начало последовательности добавьте токен `<SOS>`;\n",
        "    * в конец последовательности добавьте токен `<EOS>` и, при необходимости, несколько токенов `<PAD>`;\n",
        "  * `Dataset.__get_item__` возращает две последовательности: последовательность для обучения и правильный ответ.\n",
        "  \n",
        "  Пример:\n",
        "  ```\n",
        "  s = 'The cat sat on the mat'\n",
        "  # преобразуем в индексы\n",
        "  s_idx = [2, 5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
        "  # получаем x и y (__getitem__)\n",
        "  x = [2, 5, 1, 2, 8, 4, 7, 3, 0]\n",
        "  y = [5, 1, 2, 8, 4, 7, 3, 0, 0]\n",
        "  ```\n",
        "\n",
        "1.2 Создайте и обучите модель для генерации фамилии.\n",
        "\n",
        "  * Для преобразования последовательности индексов в последовательность векторов используйте `nn.Embedding`;\n",
        "  * Используйте рекуррентные слои;\n",
        "  * Задача ставится как предсказание следующего токена в каждом примере из пакета для каждого момента времени. Т.е. в данный момент времени по текущей подстроке предсказывает следующий символ для данной строки (задача классификации);\n",
        "  * Примерная схема реализации метода `forward`:\n",
        "  ```\n",
        "    input_X: [batch_size x seq_len] -> nn.Embedding -> emb_X: [batch_size x seq_len x embedding_size]\n",
        "    emb_X: [batch_size x seq_len x embedding_size] -> nn.RNN -> output: [batch_size x seq_len x hidden_size]\n",
        "    output: [batch_size x seq_len x hidden_size] -> torch.Tensor.reshape -> output: [batch_size * seq_len x hidden_size]\n",
        "    output: [batch_size * seq_len x hidden_size] -> nn.Linear -> output: [batch_size * seq_len x vocab_size]\n",
        "  ```\n",
        "\n",
        "1.3 Напишите функцию, которая генерирует фамилию при помощи обученной модели:\n",
        "  * Построение начинается с последовательности единичной длины, состоящей из индекса токена `<SOS>`;\n",
        "  * Начальное скрытое состояние RNN `h_t = None`;\n",
        "  * В результате прогона последнего токена из построенной последовательности через модель получаете новое скрытое состояние `h_t` и распределение над всеми токенами из словаря;\n",
        "  * Выбираете 1 токен пропорционально вероятности и добавляете его в последовательность (можно воспользоваться `torch.multinomial`);\n",
        "  * Повторяете эти действия до тех пор, пока не сгенерирован токен `<EOS>` или не превышена максимальная длина последовательности.\n",
        "\n",
        "При обучении каждые `k` эпох генерируйте несколько фамилий и выводите их на экран."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n19Y7VR-54lC",
        "outputId": "413798d8-db5f-4e17-ba16-8f34cf204e67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGGfsZxF4s_o",
        "outputId": "fcd95a74-2f87-4331-e515-0f57c79348d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Zq3LT2qQ6JmF",
        "outputId": "6d6d5ca2-93a5-4a49-9396-74564a69dabc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>авдокея</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>авдоким</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>авдоня</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>авдотька</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>авдотьюшка</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1983</th>\n",
              "      <td>ярополк</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1984</th>\n",
              "      <td>ярослав</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985</th>\n",
              "      <td>ярослава</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986</th>\n",
              "      <td>ярославка</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>яша</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1988 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            name\n",
              "0        авдокея\n",
              "1        авдоким\n",
              "2         авдоня\n",
              "3       авдотька\n",
              "4     авдотьюшка\n",
              "...          ...\n",
              "1983     ярополк\n",
              "1984     ярослав\n",
              "1985    ярослава\n",
              "1986   ярославка\n",
              "1987         яша\n",
              "\n",
              "[1988 rows x 1 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_names = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/name_rus.txt', encoding='cp1251', header=None)\n",
        "df_names = pd.read_csv('name_rus.txt', encoding='cp1251', header=None)\n",
        "df_names.columns = ['name']\n",
        "df_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEVIhWvy9nLs"
      },
      "outputs": [],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, data):\n",
        "        self.idx_to_token, self.token_to_idx = self.build_vocab(data)\n",
        "        self.vocab_len = len(self.idx_to_token)\n",
        "        self.max_seq_len = self.calculate_max_seq_len(data)\n",
        "\n",
        "    def build_vocab(self, data):\n",
        "        tokens = list()\n",
        "        tokens.append('<PAD>')\n",
        "        tokens.append('<UNK>')\n",
        "        tokens.append('<SOS>')\n",
        "        tokens.append('<EOS>')\n",
        "\n",
        "        for name in data:\n",
        "          for token in name:\n",
        "            if token not in tokens:\n",
        "                tokens.append(token.lower())\n",
        "\n",
        "        idx_to_token = {idx: token for idx, token in enumerate(tokens, start=0)}\n",
        "        token_to_idx = {token: idx for idx, token in enumerate(tokens, start=0)}\n",
        "\n",
        "        return idx_to_token, token_to_idx\n",
        "\n",
        "    def calculate_max_seq_len(self, data):\n",
        "        return max(len(name) + 2 for name in data)\n",
        "\n",
        "    def process_name(self, name):\n",
        "        indices = [self.token_to_idx['<SOS>']] + [self.token_to_idx.get(char, self.token_to_idx['<UNK>']) for char in name.lower()] + [self.token_to_idx['<EOS>']]\n",
        "        pad_length = self.max_seq_len - len(indices)\n",
        "        indices += [self.token_to_idx['<PAD>']] * pad_length\n",
        "        return indices\n",
        "\n",
        "    def indices_to_chars(self, indices):\n",
        "        return [self.idx_to_token[idx] for idx in indices]\n",
        "\n",
        "    def chars_to_indices(self, chars):\n",
        "        return [self.token_to_idx.get(char, self.token_to_idx['<UNK>']) for char in chars]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzqXY9HK9p13",
        "outputId": "f65c4ff1-c0e7-4e3c-a092-59cc9796194a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = Vocab(df_names['name'])\n",
        "vocab.max_seq_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4UcdhEC_xpc",
        "outputId": "3cc02de5-384e-4c47-d840-3442fbb7b059"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '<PAD>',\n",
              " 1: '<UNK>',\n",
              " 2: '<SOS>',\n",
              " 3: '<EOS>',\n",
              " 4: 'а',\n",
              " 5: 'в',\n",
              " 6: 'д',\n",
              " 7: 'о',\n",
              " 8: 'к',\n",
              " 9: 'е',\n",
              " 10: 'я',\n",
              " 11: 'и',\n",
              " 12: 'м',\n",
              " 13: 'н',\n",
              " 14: 'т',\n",
              " 15: 'ь',\n",
              " 16: 'ю',\n",
              " 17: 'ш',\n",
              " 18: 'х',\n",
              " 19: 'у',\n",
              " 20: 'л',\n",
              " 21: 'с',\n",
              " 22: 'г',\n",
              " 23: 'р',\n",
              " 24: 'ф',\n",
              " 25: 'п',\n",
              " 26: 'ч',\n",
              " 27: 'ы',\n",
              " 28: 'б',\n",
              " 29: 'й',\n",
              " 30: 'ж',\n",
              " 31: 'ц',\n",
              " 32: 'з',\n",
              " 33: 'э'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab.idx_to_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQK0adDeG7wl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NameDataset(Dataset):\n",
        "    def __init__(self, data, vocab):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        name = self.data[index]\n",
        "        indices = self.vocab.process_name(name)\n",
        "        x = torch.tensor(indices[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(indices[1:], dtype=torch.long)\n",
        "        return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IYtw8CN9p5y",
        "outputId": "58f2ffa6-e16d-4959-d8b9-f91e73a34b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "авдокея\n",
            "(tensor([ 2,  4,  5,  6,  7,  8,  9, 10,  3,  0,  0,  0,  0,  0]), tensor([ 4,  5,  6,  7,  8,  9, 10,  3,  0,  0,  0,  0,  0,  0]))\n"
          ]
        }
      ],
      "source": [
        "name_dataset = NameDataset(df_names['name'], vocab)\n",
        "\n",
        "print(df_names.iloc[0, 0])\n",
        "print(name_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpqYCqxA9p83"
      },
      "outputs": [],
      "source": [
        "class NameGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size, num_layers=2):\n",
        "        super(NameGenerator, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.lstm(x)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "vocab_size, embedding_size, hidden_size = vocab.vocab_len, 10, 64\n",
        "model = NameGenerator(vocab_size, embedding_size, hidden_size)\n",
        "\n",
        "vocab = Vocab(df_names['name'])\n",
        "train_dataset = NameDataset(data=df_names['name'], vocab=vocab)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.008)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbHk5n-chIaY",
        "outputId": "3d594535-feb7-4664-c133-26c92cab0090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество параметров: 55286\n"
          ]
        }
      ],
      "source": [
        "param_num = sum(p.numel() for p in model.parameters())\n",
        "print(\"Количество параметров:\", param_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDmwjpaJg2P4",
        "outputId": "3657c816-ca85-44cf-9196-9da8d2689272"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NameGenerator(\n",
              "  (embedding): Embedding(34, 10)\n",
              "  (lstm): LSTM(10, 64, num_layers=2, batch_first=True)\n",
              "  (fc1): Linear(in_features=64, out_features=34, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuX2uvdv9qAI"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dl, optimizer, criterion, vocab):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0.0\n",
        "    correct_samples = 0.0\n",
        "\n",
        "    for batch in train_dl:\n",
        "        inputs, targets = batch\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        loss = criterion(outputs.view(-1, vocab.vocab_len), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss\n",
        "        total_samples += targets.shape[0]\n",
        "\n",
        "    perplexity = 2 ** (total_loss / len(train_dl))\n",
        "    avg_loss = total_loss / len(train_dl)\n",
        "\n",
        "    return avg_loss, perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1SeZpqUdLMX"
      },
      "outputs": [],
      "source": [
        "def generate_names(model, vocab, max_length=20, num_names=20):\n",
        "    model.eval()\n",
        "\n",
        "    names_list = []\n",
        "\n",
        "    for _ in range(num_names):\n",
        "        current_token = torch.tensor([[vocab.token_to_idx['<SOS>']]], dtype=torch.long)\n",
        "        generated_name = []\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            output = model(current_token)\n",
        "\n",
        "            probabilities = torch.softmax(output[:, -1, :], dim=1)\n",
        "\n",
        "            next_token = torch.multinomial(probabilities, 1)\n",
        "\n",
        "            next_token = int(next_token.item())\n",
        "\n",
        "            if next_token == vocab.token_to_idx['<EOS>']:\n",
        "                break\n",
        "\n",
        "            if vocab.idx_to_token[next_token] not in ['<PAD>', '<UNK>', '<SOS>', '<EOS>']:\n",
        "                generated_name.append(vocab.idx_to_token[next_token])\n",
        "\n",
        "            current_token = torch.cat([current_token, torch.tensor([[next_token]], dtype=torch.long)], dim=1)\n",
        "\n",
        "        names_list.append(''.join(generated_name).capitalize())\n",
        "\n",
        "    return ', '.join(names_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1nnY_TySEfw",
        "outputId": "0f9932ce-e927-42fc-e10e-fafd003633df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch [1]: Average Loss: [1.9725], Perplexity: [3.9245],\n",
            "Generated Name: Нлиемнаяя, Жмлао, Талнмеаеан, Ллеуах, Цж, Япул, Лбхуьяв, Иртвешбрн, Хя, Хикакю, Эааи, Тгдяа, Оралаас, Луио, Шш, Яюраа, Гдиоаиар, Синоа, Ыйрряс, Викш\n",
            "epoch [2]: Average Loss: [1.3967], Perplexity: [2.6330],\n",
            "Generated Name: Ин, Дитскиьау, Рлмкыиуа, Гиа, Ешникаа, Врейна, Олмьспнаа, Зпшуана, Шеа, Вааяюя, Спуяя, Одоаха, Лгазкка, Арлмтлыраа, Оксчдяь, Алвкса, Хттускнлчй, Руаи, Лансар, Аиаанса\n",
            "epoch [3]: Average Loss: [1.2402], Perplexity: [2.3624],\n",
            "Generated Name: Арих, Ирюма, Маисиса, Гетонидя, Етм, Лраьаню, Мвароша, Редя, Дкарю, Штедюяы, Еонч, Евмаликя, Гака, Раикя, Пяраха, Вратас, Ртното, Оухи, Амуфа, Янрунткач\n",
            "epoch [4]: Average Loss: [1.0913], Perplexity: [2.1306],\n",
            "Generated Name: Сукаша, Стамя, Паник, Анша, Ансорса, Вука, Аэля, Луня, Местаска, Арлита, Видкя, Икийна, Тарана, Иоша, Таря, Оння, Восин, Сосфуша, Мкалрин, Вадя\n",
            "epoch [5]: Average Loss: [1.0505], Perplexity: [2.0712],\n",
            "Generated Name: Алол, Авелан, Пернка, Фута, Тефсюса, Птонися, Сунюхякыч, Дтюша, Векаыя, Вюлся, Вума, Вунуся, Вексипя, Ланыпя, Юма, Кионич, Ларля, Каня, Анреша, Веся\n",
            "epoch [6]: Average Loss: [1.0188], Perplexity: [2.0263],\n",
            "Generated Name: Ирека, Зокссепа, Идюся, Галя, Натеня, Паля, Мавулта, Неняха, Минтамия, Льюка, Масольким, Еидя, Нимткаха, Алеша, Тося, Есоставя, Одонба, Лареяка, Катяша, Бедасн\n",
            "epoch [7]: Average Loss: [0.9883], Perplexity: [1.9839],\n",
            "Generated Name: Тиимынка, Кузюша, Парюша, Арсна, Ватяня, Амуся, Денуха, Лина, Лаюна, Рила, Влоша, Эдовка, Адилиарка, Тахатлиня, Арзуся, Ваксга, Акапрзика, Хаса, Кануша, Дика\n",
            "epoch [8]: Average Loss: [0.9457], Perplexity: [1.9261],\n",
            "Generated Name: Евдюся, Вмовринт, Ниша, Пашула, Агелия, Вала, Ликошута, Лепань, Влаксея, Пестуля, Мирисдлич, Надюша, Анона, Элюся, Ансрюша, Ликаля, Каррена, Агнуня, Доша, Евкрела\n",
            "epoch [9]: Average Loss: [0.9108], Perplexity: [1.8800],\n",
            "Generated Name: Лина, Сустя, Татуня, Тада, Нару, Колюся, Синирьич, Мавлений, Амака, Эньина, Врилука, Тамюта, Ыруня, Ярисла, Налган, Малуша, Тина, Саня, Миррушка, Луливич\n",
            "epoch [10]: Average Loss: [0.8769], Perplexity: [1.8364],\n",
            "Generated Name: Алезона, Кюра, Витан, Никодьянюха, Вина, Афтуся, Улонинья, Наша, Петяня, Вася, Мара, Нвестуся, Нилузя, Аннаня, Китмава, Тима, Лина, Ритуля, Пеня, Алексантыик\n",
            "epoch [11]: Average Loss: [0.8474], Perplexity: [1.7992],\n",
            "Generated Name: Ната, Гавлона, Галуха, Махатяня, Илма, Заво, Деуся, Агсока, Оляха, Сорима, Лоря, Арденирка, Лався, Вретяха, Нура, Лина, Манячка, Петя, Тимюня, Даня\n",
            "epoch [12]: Average Loss: [0.8246], Perplexity: [1.7711],\n",
            "Generated Name: Китяла, Васистич, Мируля, Николеччно, Митинин, Линелима, Пануля, Тасюта, Венентич, Кинилиан, Сарья, Гана, Игуша, Веденка, Андония, Артамиса, Стеоныч, Гека, Ликиля, Нишуташа\n",
            "epoch [13]: Average Loss: [0.7901], Perplexity: [1.7292],\n",
            "Generated Name: Петюня, Санерь, Геан, Норуня, Кома, Иолинка, Иволий, Лекрипен, Тоосиня, Антоньа, Рога, Милетма, Деконя, Ммикириан, Сюта, Нишата, Вора, Тодя, Зикили, Аленка\n",
            "epoch [14]: Average Loss: [0.7679], Perplexity: [1.7028],\n",
            "Generated Name: Венисидий, Манюка, Ендуня, Валега, Федоричка, Тимаха, Ефроньья, Элюня, Торяша, Кириха, Олава, Эла, Димуня, Луша, Авдобипа, Веотоша, Катрина, Скаша, Сварина, Егуха\n",
            "epoch [15]: Average Loss: [0.7486], Perplexity: [1.6801],\n",
            "Generated Name: Вонюня, Васюта, Жанюха, Маринка, Алексий, Марохонка, Изуша, Вава, Луоня, Салия, Варила, Топай, Вианка, Геля, Вита, Витася, Васюша, Стева, Гермейа, Деня\n",
            "epoch [16]: Average Loss: [0.7272], Perplexity: [1.6554],\n",
            "Generated Name: Лавреминыч, Александрыч, Голеха, Маня, Веронша, Везяида, Элюня, Ника, Пуланя, Нюйачя, Фенуся, Мелера, Лавра, Димаря, Ануся, Натуха, Лида, Витяня, Нилуля, Лавря\n",
            "epoch [17]: Average Loss: [0.7156], Perplexity: [1.6421],\n",
            "Generated Name: Канюша, Эмелкуся, Филиппийна, Валерюшка, Геруха, Волоря, Мишоня, Иулия, Акиелинка, Алексентьяка, Адяха, Мишутатыч, Ванюта, Генуря, Василена, Аиния, Олюка, Нитилка, Фоленка, Вадинка\n",
            "epoch [18]: Average Loss: [0.7036], Perplexity: [1.6286],\n",
            "Generated Name: Ростеня, Артамоша, Моля, Алевка, Егоря, Авдебия, Ольнинья, Сюта, Борфа, Павлуся, Бося, Трера, Марея, Светнаня, Венедоня, Коргилка, Кося, Кирюня, Валерьяныч, Асюся\n",
            "epoch [19]: Average Loss: [0.6890], Perplexity: [1.6122],\n",
            "Generated Name: Миха, Теха, Андрей, Мариан, Лена, Филианка, Алга, Мина, Юлия, Дена, Машаня, Имельяньич, Амаля, Артема, Мешарюша, Никола, Алексаня, Ледя, Валентыч, Яре\n",
            "epoch [20]: Average Loss: [0.6756], Perplexity: [1.5972],\n",
            "Generated Name: Денуня, Лизана, Томуся, Никитита, Лианна, Юроня, Нада, Володюша, Рома, Алека, Лаврен, Жануха, Николична, Александрина, Тамуля, Вланят, Дашуа, Теонюля, Марго, Козя\n",
            "epoch [21]: Average Loss: [0.6770], Perplexity: [1.5988],\n",
            "Generated Name: Меша, Веня, Рюта, Галуха, Ндримуся, Даша, Аннуша, Куся, Александр, Лоруха, Кура, Асеньюшка, Иуся, Адена, Коняня, Валерьюшка, Галуша, Никита, Евгеня, Анастасьюшка\n",
            "epoch [22]: Average Loss: [0.6677], Perplexity: [1.5885],\n",
            "Generated Name: Вавуля, Мая, Андроха, Марима, Флодианыч, Артемка, Арсений, Гега, Ся, Меня, Ольбина, Христоныч, Иризка, Тася, Костюша, Матга, Нюся, Гало, Катюка, Марианка\n",
            "epoch [23]: Average Loss: [0.6642], Perplexity: [1.5847],\n",
            "Generated Name: Людмиля, Таюся, Динуся, Полека, Кристиныч, Жора, Павлуня, Варюша, Игорюша, Максимка, Петюша, Любаяида, Коняша, Лаврена, Федаша, Тоня, Рита, Вадина, Надя, Вилин\n",
            "epoch [24]: Average Loss: [0.6599], Perplexity: [1.5800],\n",
            "Generated Name: Валерья, Олебыч, Марлена, Корненя, Чоша, Нинола, Васа, Галуша, Ланя, Федюня, Лидя, Аидка, Матканка, Артем, Надюша, Алексаша, Панюся, Ванюня, Герман, Лексаша\n",
            "epoch [25]: Average Loss: [0.6641], Perplexity: [1.5846],\n",
            "Generated Name: Олена, Корниль, Ксена, Машуша, Ивания, Емилиана, Нинуля, Котя, Стеваша, Паруня, Гера, Леонтия, Стеняра, Иланюшка, Дуняха, Ирюня, Эмилия, Лавруша, Таюся, Томилия\n",
            "epoch [26]: Average Loss: [0.6478], Perplexity: [1.5668],\n",
            "Generated Name: Геруля, Максиан, Леня, Линаха, Генуша, Лена, Ларуся, Тарюха, Натоша, Росяха, Рома, Павла, Юлиана, Христуха, Дяха, Деонин, Анкаха, Санюха, Женуся, Нюна\n",
            "epoch [27]: Average Loss: [0.6422], Perplexity: [1.5607],\n",
            "Generated Name: Аполя, Лизаветка, Эля, Илия, Валенка, Варя, Ируся, Максимольич, Наруся, Вита, Севоныч, Луняка, Марьян, Наташа, Акулипа, Артамон, Милеся, Петрина, Люкаха, Нона\n",
            "epoch [28]: Average Loss: [0.6392], Perplexity: [1.5574],\n",
            "Generated Name: Даниил, Лаврентий, Аннуха, Никена, Рима, Меленка, Лукия, Тимаха, Егорка, Никитична, Людмил, Верзеаныч, Лидоша, Груша, Лака, Силвич, Евгена, Полиша, Ангеля, Панюша\n",
            "epoch [29]: Average Loss: [0.6385], Perplexity: [1.5567],\n",
            "Generated Name: Волостюша, Леонтина, Куза, Сергуша, Натальюшка, Мироня, Никула, Александр, Эллушка, Мариана, Вотюня, Николаша, Надина, Зинич, Марилья, Ефросимьюшка, Варюка, Петюша, Галлич, Дара\n",
            "epoch [30]: Average Loss: [0.6315], Perplexity: [1.5492],\n",
            "Generated Name: Германьрушка, Мишуня, Зиля, Элюня, Аринка, Натуся, Анатолька, Рет, Галя, Васса, Оза, Гана, Артамоныч, Романка, Корнилка, Димуля, Тома, Галма, Татошуня, Дашура\n",
            "epoch [31]: Average Loss: [0.6298], Perplexity: [1.5474],\n",
            "Generated Name: Стеня, Митруша, Генуля, Кирюша, Эва, Яруся, Павея, Манята, Юния, Нинонка, Витаня, Степуня, Максимильянка, Геннаида, Тама, Настуня, Аникитрей, Моня, Милетий, Лука\n",
            "epoch [32]: Average Loss: [0.6271], Perplexity: [1.5445],\n",
            "Generated Name: Дашуша, Валюня, Костяня, Анастасий, Киря, Лизавета, Акуля, Петра, Ника, Степуня, Надя, Никаша, Димуся, Юлиана, Михай, Мишата, Коша, Настасий, Василька, Диуня\n",
            "epoch [33]: Average Loss: [0.6190], Perplexity: [1.5358],\n",
            "Generated Name: Пана, Ульяныч, Аникити, Леомоха, Емельюшка, Борюся, Сонюха, Максиминична, Николич, Сененя, Овя, Ритуля, Лаврушка, Олежтюша, Тема, Галюша, Артемей, Муня, Герман, Дина\n",
            "epoch [34]: Average Loss: [0.6206], Perplexity: [1.5375],\n",
            "Generated Name: Валютя, Филюха, Евдокея, Акульвч, Кирилка, Лилия, Фрося, Голяфа, Мишура, Зкураня, Гошуня, Нинаха, Леруша, Толяха, Стеня, Вадя, Тонюта, Оля, Мала, Васюра\n",
            "epoch [35]: Average Loss: [0.6192], Perplexity: [1.5360],\n",
            "Generated Name: Ивуся, Леонич, Анто, Евгена, Корнелий, Лидя, Данил, Алектий, Сергий, Ската, Эдик, Федяха, Дашута, Еня, Валериюшка, Корниска, Муся, Мишута, Андрон, Арим\n",
            "epoch [36]: Average Loss: [0.6183], Perplexity: [1.5350],\n",
            "Generated Name: Кристина, Ритуха, Иша, Тонюня, Яша, Иваник, Душа, Элизарья, Витюля, Евгенья, Ленин, Георгич, Афросин, Ольгуся, Дося, Тарастий, Маша, Марея, Петуся, Гемилия\n",
            "epoch [37]: Average Loss: [0.6167], Perplexity: [1.5333],\n",
            "Generated Name: Данися, Дашута, Олюша, Сашуля, Даруша, Евдокипа, Мишута, Симаня, Денисия, Анастас, Митя, Лаврюха, Деня, Женя, Геннана, Евдуня, Юраха, Ленуша, Меланя, Даниила\n",
            "epoch [38]: Average Loss: [0.6143], Perplexity: [1.5308],\n",
            "Generated Name: Мура, Торя, Михай, Рибпична, Доняша, Мароша, Маргуля, Федор, Влада, Зиняидка, Генюля, Ланя, Вашуня, Вара, Вленюня, Аксюня, Елина, Нодя, Лавруся, Юнонка\n",
            "epoch [39]: Average Loss: [0.6141], Perplexity: [1.5306],\n",
            "Generated Name: Андронич, Нона, Ледюся, Минюра, Настена, Таяня, Виталия, Тимофей, Нюнейка, Филя, Тотя, Полина, Ванята, Леонна, Христиана, Еню, Васята, Рома, Алевтинка, Тамара\n",
            "epoch [40]: Average Loss: [0.6076], Perplexity: [1.5237],\n",
            "Generated Name: Леонина, Данилыч, Марина, Виктория, Конон, Артефина, Анша, Илюся, Антонинка, Линуся, Лана, Петруся, Аднефий, Евген, Макся, Леонард, Динуся, Глюба, Вита, Юлиюся\n",
            "epoch [41]: Average Loss: [0.6031], Perplexity: [1.5190],\n",
            "Generated Name: Евгеня, Эва, Олеюня, Света, Таися, Евгеньюхка, Эмиля, Ираша, Гошуша, Нила, Аледя, Пуся, Ладя, Аннуша, Витушка, Владиславка, Сона, Борюха, Киря, Рустя\n",
            "epoch [42]: Average Loss: [0.6017], Perplexity: [1.5175],\n",
            "Generated Name: Миланка, Акулина, Андрей, Ликюся, Лаврюня, Полюта, Юлчич, Стюня, Ефросиния, Марлена, Жанюся, Захар, Маюня, Поликсена, Федяка, Митюла, Наткаша, Алеша, Полинарий, Лера\n",
            "epoch [43]: Average Loss: [0.6018], Perplexity: [1.5176],\n",
            "Generated Name: Тюня, Юля, Куляша, Вячеслав, Нона, Мишура, Катюха, Емилианыч, Денис, Евдокимыч, Тама, Романя, Варютей, Алеша, Инуха, Вероня, Иулианыч, Василинка, Надамка, Риславла\n",
            "epoch [44]: Average Loss: [0.5998], Perplexity: [1.5155],\n",
            "Generated Name: Емилиан, Михаил, Арюха, Наталий, Андрон, Дионикит, Панюра, Надена, Васильич, Николай, Пана, Игоряша, Миня, Василинка, Олеха, Юраша, Вира, Сила, Ланя, Таюша\n",
            "epoch [45]: Average Loss: [0.6027], Perplexity: [1.5186],\n",
            "Generated Name: Никитка, Игорюха, Володюня, Геруха, Мика, Артамон, Егорыч, Кирилич, Петаха, Авдуся, Желика, Петюня, Леонт, Викторка, Петряня, Николя, Антуша, Артен, Николя, Ульянка\n",
            "epoch [46]: Average Loss: [0.5971], Perplexity: [1.5127],\n",
            "Generated Name: Мелаша, Веня, Олюся, Костюня, Мукил, Петяша, Андроныч, Ираидка, Васюта, Емилиан, Лександр, Антя, Симаня, Гоша, Генюха, Володюка, Эдуся, Сергуля, Елюня, Алюня\n",
            "epoch [47]: Average Loss: [0.5989], Perplexity: [1.5145],\n",
            "Generated Name: Эммануил, Степа, Антоха, Максиан, Александринка, Арсюша, Василей, Валерьян, Митрич, Лин, Анастасий, Леля, Васа, Маханя, Вадимка, Василина, Линуха, Бена, Марюха, Галлии\n",
            "epoch [48]: Average Loss: [0.6018], Perplexity: [1.5176],\n",
            "Generated Name: Петруня, Адам, Римма, Лида, Сенюра, Альбиныч, Лилюся, Бенедикта, Марлен, Альбиныч, Зиня, Полинкуша, Николка, Иваха, Грипа, Христюня, Петнюша, Маюша, Декася, Леня\n",
            "epoch [49]: Average Loss: [0.5996], Perplexity: [1.5153],\n",
            "Generated Name: Аграфенка, Леонтий, Веня, Бася, Лина, Даха, Владимир, Гера, Оксаха, Нюраша, Генуша, Маолена, Лавря, Максим, Зинаида, Роберст, Нуша, Маланья, Николай, Эльвирка\n",
            "epoch [50]: Average Loss: [0.5949], Perplexity: [1.5104],\n",
            "Generated Name: Константинка, Петруша, Люба, Ольгуня, Андрона, Таюша, Нинлуша, Римуля, Котяха, Илья, Лида, Никиша, Павлуся, Костюня, Петряша, Катя, Коньям, Максюша, Сергиян, Ткоря\n"
          ]
        }
      ],
      "source": [
        "losses_train, losses_test = [], []\n",
        "for epoch in range(50):\n",
        "    total_loss_train, perplexity = train(model, train_loader, optimizer, criterion, vocab)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    # total_loss_test, test_accuracy = test(model, test_loader, criterion, vocab)\n",
        "    # losses_test.append(total_loss_test.item())\n",
        "    print(f\"epoch [{epoch+1}]: Average Loss: [{total_loss_train:.4f}], Perplexity: [{perplexity:.4f}],\")\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        generated_name = generate_names(model, vocab)\n",
        "        print(f\"Generated Name: {generated_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WrLFgr4cVsc",
        "outputId": "169d4ff3-8d95-4025-ad46-5ecce504708f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Name: Константинка, Килина, Сенюра, Валюха, Элизуня, Александра, Яда, Игорыч, Танюша, Килинка, Петруня, Захарий, Лавреныч, Емиля, Аруся, Веруся, Эмиля, Андрейка, Тонюся, Владислава\n"
          ]
        }
      ],
      "source": [
        "def generate_names(model, vocab, max_length=20, num_names=20):\n",
        "    model.eval()\n",
        "\n",
        "    names_list = []\n",
        "\n",
        "    for _ in range(num_names):\n",
        "        current_token = torch.tensor([[vocab.token_to_idx['<SOS>']]], dtype=torch.long)\n",
        "        generated_name = []\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            output = model(current_token)\n",
        "\n",
        "            probabilities = torch.softmax(output[:, -1, :], dim=1)\n",
        "\n",
        "            next_token = torch.multinomial(probabilities, 1)\n",
        "\n",
        "            # Convert the sampled token to a Python integer\n",
        "            next_token = int(next_token.item())\n",
        "\n",
        "            if next_token == vocab.token_to_idx['<EOS>']:\n",
        "                break\n",
        "\n",
        "            # Check if the sampled token is not a special symbol\n",
        "            if vocab.idx_to_token[next_token] not in ['<PAD>', '<UNK>', '<SOS>', '<EOS>']:\n",
        "                # Append the sampled token to the generated surname\n",
        "                generated_name.append(vocab.idx_to_token[next_token])\n",
        "\n",
        "            current_token = torch.cat([current_token, torch.tensor([[next_token]], dtype=torch.long)], dim=1)\n",
        "\n",
        "        names_list.append(''.join(generated_name).capitalize())\n",
        "\n",
        "    return ', '.join(names_list)\n",
        "\n",
        "\n",
        "    return ', '.join(names_list)\n",
        "generated_name = generate_names(model, vocab)\n",
        "print(f\"Generated Name: {generated_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJf5iaA2fOTM"
      },
      "source": [
        "## 2. Генерирование текста при помощи RNN\n",
        "\n",
        "2.1 Скачайте из интернета какое-нибудь художественное произведение\n",
        "  * Выбирайте достаточно крупное произведение, чтобы модель лучше обучалась;\n",
        "\n",
        "2.2 На основе выбранного произведения создайте датасет.\n",
        "\n",
        "Отличия от задачи 1:\n",
        "  * Токены <SOS>, `<EOS>` и `<UNK>` можно не добавлять;\n",
        "  * При создании датасета текст необходимо предварительно разбить на части. Выберите желаемую длину последовательности `seq_len` и разбейте текст на построки длины `seq_len` (можно без перекрытия, можно с небольшим перекрытием).\n",
        "\n",
        "2.3 Создайте и обучите модель для генерации текста\n",
        "  * Задача ставится точно так же как в 1.2;\n",
        "  * При необходимости можете применить:\n",
        "    * двухуровневые рекуррентные слои (`num_layers`=2)\n",
        "    * [обрезку градиентов](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)\n",
        "\n",
        "2.4 Напишите функцию, которая генерирует фрагмент текста при помощи обученной модели\n",
        "  * Процесс генерации начинается с небольшого фрагмента текста `prime`, выбранного вами (1-2 слова)\n",
        "  * Сначала вы пропускаете через модель токены из `prime` и генерируете на их основе скрытое состояние рекуррентного слоя `h_t`;\n",
        "  * После этого вы генерируете строку нужной длины аналогично 1.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHz9gjhOksJN"
      },
      "source": [
        "**Генерация на основе слов**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "nsuS4NKe4b54",
        "outputId": "f53aee2a-7fd5-45d5-919e-e1d8445d1616"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'приятного чтения лев толстой война и мир шедевр мировой литературы в одном томе том первый часть первая 234 поместья 233 233 234 234 мой верный раб 1 ну князь генуя и лукка поместья фамилии бонапарте нет я вам вперед говорю если вы мне не скажете что у нас война если вы еще позволите себе защищать все гадости все ужасы этого антихриста право я верю что он антихрист я вас больше не знаю вы уж не друг мой вы уж не мой верный раб как вы говорите франц в дальнейшем переводы с французского не оговариваются здесь и далее все переводы кроме специально оговоренных принадлежат л н толстому ред ну здравствуйте здравствуйте 2 я вижу что я вас пугаю садитесь и рассказывайте так говорила в июле 1805 года известная анна павловна шерер фрейлина и приближенная императрицы марии феодоровны встречая важного и чиновного князя василия первого приехавшего на ее вечер анна павловна кашляла несколько дней у нее был грипп как она говорила грипп был тогда новое слово употреблявшееся только редкими в записочках'"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"Толстой Лев. Война и мир. Шедевр мировой литературы в одном томе - royallib.com.txt\", \"r\", encoding=\"cp1251\") as file:\n",
        "    text = file.read().replace('\\n', ' ').lower()\n",
        "    text = re.sub(r'[^а-яА-ЯёЁ0-9]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "text[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRYwZfGYmXKG",
        "outputId": "c92e728d-ddd3-41a5-9010-946111ca9c37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "464110"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7wejKXci9V3"
      },
      "outputs": [],
      "source": [
        "text = text.split()[150000:200000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bas024cNnOio",
        "outputId": "afbc7c77-642c-42d0-9cb9-35bfa155e499"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hQTCzIjx2AkI",
        "outputId": "2e6dceca-66b9-4dc5-d9de-eb809042d9dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[парадной, форме, мимо, которых, ему, надо, бы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[форме, мимо, которых, ему, надо, было, пройти...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[мимо, которых, ему, надо, было, пройти, прокл...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[которых, ему, надо, было, пройти, проклиная, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ему, надо, было, пройти, проклиная, свою, сме...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49946</th>\n",
              "      <td>[на, другой, день, князь, ни, слова, не, сказа...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49947</th>\n",
              "      <td>[другой, день, князь, ни, слова, не, сказал, с...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49948</th>\n",
              "      <td>[день, князь, ни, слова, не, сказал, своей, до...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49949</th>\n",
              "      <td>[князь, ни, слова, не, сказал, своей, дочери, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49950</th>\n",
              "      <td>[ни, слова, не, сказал, своей, дочери, но, она...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49951 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sequences\n",
              "0      [парадной, форме, мимо, которых, ему, надо, бы...\n",
              "1      [форме, мимо, которых, ему, надо, было, пройти...\n",
              "2      [мимо, которых, ему, надо, было, пройти, прокл...\n",
              "3      [которых, ему, надо, было, пройти, проклиная, ...\n",
              "4      [ему, надо, было, пройти, проклиная, свою, сме...\n",
              "...                                                  ...\n",
              "49946  [на, другой, день, князь, ни, слова, не, сказа...\n",
              "49947  [другой, день, князь, ни, слова, не, сказал, с...\n",
              "49948  [день, князь, ни, слова, не, сказал, своей, до...\n",
              "49949  [князь, ни, слова, не, сказал, своей, дочери, ...\n",
              "49950  [ни, слова, не, сказал, своей, дочери, но, она...\n",
              "\n",
              "[49951 rows x 1 columns]"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seq_len = 50\n",
        "step_size = 1\n",
        "\n",
        "def create_dataset(text, seq_len, step_size):\n",
        "    sequences = []\n",
        "    for i in range(0, len(text) - seq_len + 1, step_size):\n",
        "        seq = text[i : i + seq_len]\n",
        "        sequences.append(seq)\n",
        "\n",
        "    df = pd.DataFrame({'sequences': sequences})\n",
        "    return df\n",
        "\n",
        "df_sequences = create_dataset(text, seq_len, step_size)\n",
        "df_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wlt11DsltLX",
        "outputId": "35f6db13-0a1c-4b40-df53-e6fa784f64c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11785"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, data):\n",
        "        self.idx_to_token, self.token_to_idx = self.build_vocab(data)\n",
        "        self.vocab_len = len(self.idx_to_token)\n",
        "        self.max_seq_len = self.calculate_max_seq_len(data)\n",
        "\n",
        "    def build_vocab(self, data):\n",
        "        tokens = list()\n",
        "        tokens.append('<PAD>')\n",
        "        tokens.append('<SOS>')\n",
        "\n",
        "\n",
        "        for seq in data:\n",
        "          for token in seq:\n",
        "            if token not in tokens:\n",
        "                tokens.append(token)\n",
        "\n",
        "        idx_to_token = {idx: token for idx, token in enumerate(tokens, start=0)}\n",
        "        token_to_idx = {token: idx for idx, token in enumerate(tokens, start=0)}\n",
        "\n",
        "        return idx_to_token, token_to_idx\n",
        "\n",
        "    def calculate_max_seq_len(self, data):\n",
        "        return max(len(seq) + 2 for seq in data)\n",
        "\n",
        "    def process_text(self, seq):\n",
        "        indices = [self.token_to_idx['<SOS>']] + [self.token_to_idx.get(char) for char in seq]\n",
        "        pad_length = self.max_seq_len - len(indices)\n",
        "        indices += [self.token_to_idx['<PAD>']] * pad_length\n",
        "        return indices\n",
        "\n",
        "    def indices_to_chars(self, indices):\n",
        "        return [self.idx_to_token[idx] for idx in indices]\n",
        "\n",
        "    def chars_to_indices(self, chars):\n",
        "        return [self.token_to_idx.get(char) for char in chars]\n",
        "\n",
        "vocab = Vocab(df_sequences['sequences'])\n",
        "vocab.vocab_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8_wbL8anRZt",
        "outputId": "ac858534-abcd-4e92-dbbc-93b4bfd101ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: '<PAD>',\n",
              " 1: '<SOS>',\n",
              " 2: 'парадной',\n",
              " 3: 'форме',\n",
              " 4: 'мимо',\n",
              " 5: 'которых',\n",
              " 6: 'ему',\n",
              " 7: 'надо',\n",
              " 8: 'было',\n",
              " 9: 'пройти',\n",
              " 10: 'проклиная',\n",
              " 11: 'свою',\n",
              " 12: 'смелость',\n",
              " 13: 'замирая',\n",
              " 14: 'от',\n",
              " 15: 'мысли',\n",
              " 16: 'что',\n",
              " 17: 'всякую',\n",
              " 18: 'минуту',\n",
              " 19: 'он',\n",
              " 20: 'может',\n",
              " 21: 'встретить',\n",
              " 22: 'государя',\n",
              " 23: 'и',\n",
              " 24: 'при',\n",
              " 25: 'нем',\n",
              " 26: 'быть',\n",
              " 27: 'осрамлен',\n",
              " 28: 'выслан',\n",
              " 29: 'под',\n",
              " 30: 'арест',\n",
              " 31: 'понимая',\n",
              " 32: 'вполне',\n",
              " 33: 'всю',\n",
              " 34: 'неприличность',\n",
              " 35: 'своего',\n",
              " 36: 'поступка',\n",
              " 37: 'раскаиваясь',\n",
              " 38: 'в',\n",
              " 39: 'ростов',\n",
              " 40: 'опустив',\n",
              " 41: 'глаза',\n",
              " 42: 'пробирался',\n",
              " 43: 'вон',\n",
              " 44: 'из',\n",
              " 45: 'дома',\n",
              " 46: 'окруженного',\n",
              " 47: 'толпой',\n",
              " 48: 'блестящей',\n",
              " 49: 'свиты',\n",
              " 50: 'когда',\n",
              " 51: 'чей',\n",
              " 52: 'то',\n",
              " 53: 'знакомый',\n",
              " 54: 'голос',\n",
              " 55: 'окликнул',\n",
              " 56: 'его',\n",
              " 57: 'чья',\n",
              " 58: 'рука',\n",
              " 59: 'остановила',\n",
              " 60: 'вы',\n",
              " 61: 'батюшка',\n",
              " 62: 'тут',\n",
              " 63: 'делаете',\n",
              " 64: 'во',\n",
              " 65: 'фраке',\n",
              " 66: 'спросил',\n",
              " 67: 'басистый',\n",
              " 68: 'это',\n",
              " 69: 'был',\n",
              " 70: 'кавалерийский',\n",
              " 71: 'генерал',\n",
              " 72: 'эту',\n",
              " 73: 'кампанию',\n",
              " 74: 'заслуживший',\n",
              " 75: 'особую',\n",
              " 76: 'милость',\n",
              " 77: 'бывший',\n",
              " 78: 'начальник',\n",
              " 79: 'дивизии',\n",
              " 80: 'которой',\n",
              " 81: 'служил',\n",
              " 82: 'испуганно',\n",
              " 83: 'начал',\n",
              " 84: 'оправдываться',\n",
              " 85: 'но',\n",
              " 86: 'увидав',\n",
              " 87: 'добродушно',\n",
              " 88: 'шутливое',\n",
              " 89: 'лицо',\n",
              " 90: 'генерала',\n",
              " 91: 'отойдя',\n",
              " 92: 'к',\n",
              " 93: 'стороне',\n",
              " 94: 'взволнованным',\n",
              " 95: 'голосом',\n",
              " 96: 'передал',\n",
              " 97: 'все',\n",
              " 98: 'дело',\n",
              " 99: 'прося',\n",
              " 100: 'заступиться',\n",
              " 101: 'за',\n",
              " 102: 'известного',\n",
              " 103: 'генералу',\n",
              " 104: 'денисова',\n",
              " 105: 'выслушав',\n",
              " 106: 'ростова',\n",
              " 107: 'серьезно',\n",
              " 108: 'покачал',\n",
              " 109: 'головой',\n",
              " 110: 'жалко',\n",
              " 111: 'молодца',\n",
              " 112: 'давай',\n",
              " 113: 'письмо',\n",
              " 114: 'едва',\n",
              " 115: 'успел',\n",
              " 116: 'передать',\n",
              " 117: 'рассказать',\n",
              " 118: 'как',\n",
              " 119: 'с',\n",
              " 120: 'лестницы',\n",
              " 121: 'застучали',\n",
              " 122: 'быстрые',\n",
              " 123: 'шаги',\n",
              " 124: 'со',\n",
              " 125: 'шпорами',\n",
              " 126: 'него',\n",
              " 127: 'подвинулся',\n",
              " 128: 'крыльцу',\n",
              " 129: 'господа',\n",
              " 130: 'сбежали',\n",
              " 131: 'пошли',\n",
              " 132: 'лошадям',\n",
              " 133: 'берейтор',\n",
              " 134: 'эне',\n",
              " 135: 'тот',\n",
              " 136: 'самый',\n",
              " 137: 'который',\n",
              " 138: 'аустерлице',\n",
              " 139: 'подвел',\n",
              " 140: 'лошадь',\n",
              " 141: 'на',\n",
              " 142: 'лестнице',\n",
              " 143: 'послышался',\n",
              " 144: 'легкий',\n",
              " 145: 'скрип',\n",
              " 146: 'шагов',\n",
              " 147: 'которые',\n",
              " 148: 'сейчас',\n",
              " 149: 'узнал',\n",
              " 150: 'забыв',\n",
              " 151: 'опасность',\n",
              " 152: 'узнанным',\n",
              " 153: 'несколькими',\n",
              " 154: 'любопытными',\n",
              " 155: 'жителей',\n",
              " 156: 'самому',\n",
              " 157: 'опять',\n",
              " 158: 'после',\n",
              " 159: 'двух',\n",
              " 160: 'лет',\n",
              " 161: 'увидал',\n",
              " 162: 'те',\n",
              " 163: 'же',\n",
              " 164: 'обожаемые',\n",
              " 165: 'им',\n",
              " 166: 'черты',\n",
              " 167: 'взгляд',\n",
              " 168: 'ту',\n",
              " 169: 'походку',\n",
              " 170: 'соединение',\n",
              " 171: 'величия',\n",
              " 172: 'кротости',\n",
              " 173: 'чувство',\n",
              " 174: 'восторга',\n",
              " 175: 'любви',\n",
              " 176: 'государю',\n",
              " 177: 'прежнею',\n",
              " 178: 'силою',\n",
              " 179: 'воскресло',\n",
              " 180: 'душе',\n",
              " 181: 'государь',\n",
              " 182: 'преображенском',\n",
              " 183: 'мундире',\n",
              " 184: 'белых',\n",
              " 185: 'лосинах',\n",
              " 186: 'высоких',\n",
              " 187: 'ботфортах',\n",
              " 188: 'звездой',\n",
              " 189: 'которую',\n",
              " 190: 'не',\n",
              " 191: 'знал',\n",
              " 192: 'была',\n",
              " 193: '233',\n",
              " 194: '437',\n",
              " 195: 'звезда',\n",
              " 196: 'почетного',\n",
              " 197: 'легиона',\n",
              " 198: 'вышел',\n",
              " 199: 'крыльцо',\n",
              " 200: 'держа',\n",
              " 201: 'шляпу',\n",
              " 202: 'рукой',\n",
              " 203: 'надевая',\n",
              " 204: 'перчатку',\n",
              " 205: 'остановился',\n",
              " 206: 'оглядываясь',\n",
              " 207: 'освещая',\n",
              " 208: 'вокруг',\n",
              " 209: 'себя',\n",
              " 210: 'своим',\n",
              " 211: 'взглядом',\n",
              " 212: 'кое',\n",
              " 213: 'кому',\n",
              " 214: 'генералов',\n",
              " 215: 'сказал',\n",
              " 216: 'несколько',\n",
              " 217: 'слов',\n",
              " 218: 'тоже',\n",
              " 219: 'бывшего',\n",
              " 220: 'начальника',\n",
              " 221: 'улыбнулся',\n",
              " 222: 'подозвал',\n",
              " 223: 'себе',\n",
              " 224: 'вся',\n",
              " 225: 'свита',\n",
              " 226: 'отступила',\n",
              " 227: 'видел',\n",
              " 228: 'этот',\n",
              " 229: 'довольно',\n",
              " 230: 'долго',\n",
              " 231: 'говорил',\n",
              " 232: 'сделал',\n",
              " 233: 'шаг',\n",
              " 234: 'чтобы',\n",
              " 235: 'подойти',\n",
              " 236: 'лошади',\n",
              " 237: 'толпа',\n",
              " 238: 'улицы',\n",
              " 239: 'придвинулась',\n",
              " 240: 'остановившись',\n",
              " 241: 'у',\n",
              " 242: 'взявшись',\n",
              " 243: 'рукою',\n",
              " 244: 'седло',\n",
              " 245: 'обратился',\n",
              " 246: 'кавалерийскому',\n",
              " 247: 'громко',\n",
              " 248: 'очевидно',\n",
              " 249: 'желанием',\n",
              " 250: 'слышали',\n",
              " 251: 'могу',\n",
              " 252: 'потому',\n",
              " 253: 'закон',\n",
              " 254: 'сильнее',\n",
              " 255: 'меня',\n",
              " 256: 'занес',\n",
              " 257: 'ногу',\n",
              " 258: 'стремя',\n",
              " 259: 'почтительно',\n",
              " 260: 'наклонил',\n",
              " 261: 'голову',\n",
              " 262: 'сел',\n",
              " 263: 'поехал',\n",
              " 264: 'галопом',\n",
              " 265: 'по',\n",
              " 266: 'улице',\n",
              " 267: 'помня',\n",
              " 268: 'толпою',\n",
              " 269: 'побежал',\n",
              " 270: 'ним',\n",
              " 271: 'площади',\n",
              " 272: 'куда',\n",
              " 273: 'стояли',\n",
              " 274: 'лицом',\n",
              " 275: 'лицу',\n",
              " 276: 'справа',\n",
              " 277: 'батальон',\n",
              " 278: 'преображенцев',\n",
              " 279: 'слева',\n",
              " 280: 'французской',\n",
              " 281: 'гвардии',\n",
              " 282: 'медвежьих',\n",
              " 283: 'шапках',\n",
              " 284: 'время',\n",
              " 285: 'подъезжал',\n",
              " 286: 'одному',\n",
              " 287: 'флангу',\n",
              " 288: 'батальонов',\n",
              " 289: 'сделавших',\n",
              " 290: 'караул',\n",
              " 291: 'противоположному',\n",
              " 292: 'подскакивала',\n",
              " 293: 'другая',\n",
              " 294: 'всадников',\n",
              " 295: 'впереди',\n",
              " 296: 'их',\n",
              " 297: 'наполеона',\n",
              " 298: 'мог',\n",
              " 299: 'никто',\n",
              " 300: 'другой',\n",
              " 301: 'ехал',\n",
              " 302: 'маленькой',\n",
              " 303: 'шляпе',\n",
              " 304: 'андреевской',\n",
              " 305: 'лентой',\n",
              " 306: 'через',\n",
              " 307: 'плечо',\n",
              " 308: 'раскрытом',\n",
              " 309: 'над',\n",
              " 310: 'белым',\n",
              " 311: 'камзолом',\n",
              " 312: 'синем',\n",
              " 313: 'необыкновенно',\n",
              " 314: 'породистой',\n",
              " 315: 'арабской',\n",
              " 316: 'серой',\n",
              " 317: 'малиновом',\n",
              " 318: 'золотом',\n",
              " 319: 'шитом',\n",
              " 320: 'чепраке',\n",
              " 321: 'подъехав',\n",
              " 322: 'александру',\n",
              " 323: 'приподнял',\n",
              " 324: 'этом',\n",
              " 325: 'движении',\n",
              " 326: 'глаз',\n",
              " 327: 'заметить',\n",
              " 328: 'наполеон',\n",
              " 329: 'дурно',\n",
              " 330: 'нетвердо',\n",
              " 331: 'сидел',\n",
              " 332: 'батальоны',\n",
              " 333: 'закричали',\n",
              " 334: 'ура',\n",
              " 335: '438',\n",
              " 336: 'виват',\n",
              " 337: 'император',\n",
              " 338: 'оба',\n",
              " 339: 'императора',\n",
              " 340: 'слезли',\n",
              " 341: 'лошадей',\n",
              " 342: 'взяли',\n",
              " 343: 'друг',\n",
              " 344: 'друга',\n",
              " 345: 'руки',\n",
              " 346: 'лице',\n",
              " 347: 'неприятно',\n",
              " 348: 'притворная',\n",
              " 349: 'улыбка',\n",
              " 350: 'александр',\n",
              " 351: 'ласковым',\n",
              " 352: 'выражением',\n",
              " 353: 'спуская',\n",
              " 354: 'несмотря',\n",
              " 355: 'топтание',\n",
              " 356: 'лошадьми',\n",
              " 357: 'французских',\n",
              " 358: 'жандармов',\n",
              " 359: 'осаживавших',\n",
              " 360: 'толпу',\n",
              " 361: 'следил',\n",
              " 362: 'каждым',\n",
              " 363: 'движением',\n",
              " 364: 'александра',\n",
              " 365: 'бонапарте',\n",
              " 366: 'неожиданность',\n",
              " 367: 'поразило',\n",
              " 368: 'держал',\n",
              " 369: 'равный',\n",
              " 370: 'совершенно',\n",
              " 371: 'свободно',\n",
              " 372: 'будто',\n",
              " 373: 'эта',\n",
              " 374: 'близость',\n",
              " 375: 'государем',\n",
              " 376: 'естественна',\n",
              " 377: 'привычна',\n",
              " 378: 'обращался',\n",
              " 379: 'русским',\n",
              " 380: 'царем',\n",
              " 381: 'длинным',\n",
              " 382: 'хвостом',\n",
              " 383: 'подошли',\n",
              " 384: 'правому',\n",
              " 385: 'преображенского',\n",
              " 386: 'батальона',\n",
              " 387: 'прямо',\n",
              " 388: 'которая',\n",
              " 389: 'стояла',\n",
              " 390: 'очутилась',\n",
              " 391: 'неожиданно',\n",
              " 392: 'так',\n",
              " 393: 'близко',\n",
              " 394: 'императорам',\n",
              " 395: 'ростову',\n",
              " 396: 'стоявшему',\n",
              " 397: 'передних',\n",
              " 398: 'рядах',\n",
              " 399: 'ее',\n",
              " 400: 'стало',\n",
              " 401: 'страшно',\n",
              " 402: 'бы',\n",
              " 403: 'узнали',\n",
              " 404: '439',\n",
              " 405: 'я',\n",
              " 406: 'прошу',\n",
              " 407: 'вашего',\n",
              " 408: 'позволения',\n",
              " 409: 'дать',\n",
              " 410: 'орден',\n",
              " 411: 'храбрейшему',\n",
              " 412: 'ваших',\n",
              " 413: 'солдат',\n",
              " 414: 'резкий',\n",
              " 415: 'точный',\n",
              " 416: 'договаривающий',\n",
              " 417: 'каждую',\n",
              " 418: 'букву',\n",
              " 419: 'малый',\n",
              " 420: 'ростом',\n",
              " 421: 'снизу',\n",
              " 422: 'глядя',\n",
              " 423: 'внимательно',\n",
              " 424: 'слушал',\n",
              " 425: 'говорили',\n",
              " 426: 'наклонив',\n",
              " 427: 'приятно',\n",
              " 428: '232',\n",
              " 429: '440',\n",
              " 430: 'тому',\n",
              " 431: 'кто',\n",
              " 432: 'храбрее',\n",
              " 433: 'всех',\n",
              " 434: 'вел',\n",
              " 435: 'войну',\n",
              " 436: 'прибавил',\n",
              " 437: 'отчеканивая',\n",
              " 438: 'каждый',\n",
              " 439: 'слог',\n",
              " 440: 'возмутительным',\n",
              " 441: 'для',\n",
              " 442: 'спокойствием',\n",
              " 443: 'уверенностью',\n",
              " 444: 'оглядывая',\n",
              " 445: 'ряды',\n",
              " 446: 'русских',\n",
              " 447: 'вытянувшихся',\n",
              " 448: 'перед',\n",
              " 449: 'всё',\n",
              " 450: 'держащих',\n",
              " 451: 'неподвижно',\n",
              " 452: 'глядящих',\n",
              " 453: '441',\n",
              " 454: 'позвольте',\n",
              " 455: 'мне',\n",
              " 456: 'ваше',\n",
              " 457: 'величество',\n",
              " 458: 'спросить',\n",
              " 459: 'мнение',\n",
              " 460: 'полковника',\n",
              " 461: 'поспешных',\n",
              " 462: 'князю',\n",
              " 463: 'козловскому',\n",
              " 464: 'командиру',\n",
              " 465: 'между',\n",
              " 466: 'тем',\n",
              " 467: 'стал',\n",
              " 468: 'снимать',\n",
              " 469: 'белой',\n",
              " 470: 'разорвав',\n",
              " 471: 'бросил',\n",
              " 472: 'адъютант',\n",
              " 473: 'сзади',\n",
              " 474: 'торопливо',\n",
              " 475: 'бросившись',\n",
              " 476: 'вперед',\n",
              " 477: 'поднял',\n",
              " 478: 'русски',\n",
              " 479: 'козловского',\n",
              " 480: 'прикажете',\n",
              " 481: 'недовольно',\n",
              " 482: 'поморщился',\n",
              " 483: 'оглянувшись',\n",
              " 484: 'да',\n",
              " 485: 'ведь',\n",
              " 486: 'надобно',\n",
              " 487: 'отвечать',\n",
              " 488: 'козловский',\n",
              " 489: 'решительным',\n",
              " 490: 'видом',\n",
              " 491: 'оглянулся',\n",
              " 492: 'взгляде',\n",
              " 493: 'захватил',\n",
              " 494: 'уж',\n",
              " 495: 'ли',\n",
              " 496: 'подумал',\n",
              " 497: 'лазарев',\n",
              " 498: 'нахмурившись',\n",
              " 499: 'прокомандовал',\n",
              " 500: 'полковник',\n",
              " 501: 'первый',\n",
              " 502: 'ранжиру',\n",
              " 503: 'бойко',\n",
              " 504: 'ж',\n",
              " 505: 'ты',\n",
              " 506: 'стой',\n",
              " 507: 'зашептали',\n",
              " 508: 'голоса',\n",
              " 509: 'лазарева',\n",
              " 510: 'знавшего',\n",
              " 511: 'идти',\n",
              " 512: 'покосившись',\n",
              " 513: 'дрогнуло',\n",
              " 514: 'бывает',\n",
              " 515: 'солдатами',\n",
              " 516: 'вызываемыми',\n",
              " 517: 'фронт',\n",
              " 518: 'чуть',\n",
              " 519: 'поворотил',\n",
              " 520: 'назад',\n",
              " 521: 'отвел',\n",
              " 522: 'маленькую',\n",
              " 523: 'пухлую',\n",
              " 524: 'ручку',\n",
              " 525: 'желая',\n",
              " 526: 'взять',\n",
              " 527: 'лица',\n",
              " 528: 'догадавшись',\n",
              " 529: 'секунду',\n",
              " 530: 'чем',\n",
              " 531: 'засуетились',\n",
              " 532: 'зашептались',\n",
              " 533: 'передавая',\n",
              " 534: 'один',\n",
              " 535: 'другому',\n",
              " 536: 'паж',\n",
              " 537: 'которого',\n",
              " 538: 'вчера',\n",
              " 539: 'бориса',\n",
              " 540: 'выбежал',\n",
              " 541: 'наклонившись',\n",
              " 542: 'протянутой',\n",
              " 543: 'заставив',\n",
              " 544: 'дожидаться',\n",
              " 545: 'ни',\n",
              " 546: 'одной',\n",
              " 547: 'секунды',\n",
              " 548: 'вложил',\n",
              " 549: 'нее',\n",
              " 550: 'красной',\n",
              " 551: 'ленте',\n",
              " 552: 'сжал',\n",
              " 553: 'два',\n",
              " 554: 'пальца',\n",
              " 555: 'очутился',\n",
              " 556: 'ними',\n",
              " 557: 'подошел',\n",
              " 558: 'лазареву',\n",
              " 559: 'выкатывая',\n",
              " 560: 'упорно',\n",
              " 561: 'продолжал',\n",
              " 562: 'смотреть',\n",
              " 563: 'только',\n",
              " 564: 'показывая',\n",
              " 565: 'этим',\n",
              " 566: 'делал',\n",
              " 567: 'теперь',\n",
              " 568: 'союзника',\n",
              " 569: 'маленькая',\n",
              " 570: 'белая',\n",
              " 571: 'орденом',\n",
              " 572: 'дотронулась',\n",
              " 573: 'до',\n",
              " 574: 'пуговицы',\n",
              " 575: 'солдата',\n",
              " 576: 'того',\n",
              " 577: 'навсегда',\n",
              " 578: 'счастлив',\n",
              " 579: 'награжден',\n",
              " 580: 'отличен',\n",
              " 581: 'мире',\n",
              " 582: 'нужно',\n",
              " 583: 'чтоб',\n",
              " 584: 'наполеонова',\n",
              " 585: 'удостоила',\n",
              " 586: 'дотронуться',\n",
              " 587: 'груди',\n",
              " 588: 'приложил',\n",
              " 589: 'крест',\n",
              " 590: 'пустив',\n",
              " 591: 'руку',\n",
              " 592: 'должен',\n",
              " 593: 'прилипнуть',\n",
              " 594: 'действительно',\n",
              " 595: 'прилип',\n",
              " 596: 'русские',\n",
              " 597: 'французские',\n",
              " 598: 'услужливые',\n",
              " 599: 'мгновенно',\n",
              " 600: 'подхватив',\n",
              " 601: 'прицепили',\n",
              " 602: 'мундиру',\n",
              " 603: 'мрачно',\n",
              " 604: 'взглянул',\n",
              " 605: 'маленького',\n",
              " 606: 'человека',\n",
              " 607: 'белыми',\n",
              " 608: 'руками',\n",
              " 609: 'продолжая',\n",
              " 610: 'держать',\n",
              " 611: 'глядеть',\n",
              " 612: 'спрашивал',\n",
              " 613: 'еще',\n",
              " 614: 'стоять',\n",
              " 615: 'или',\n",
              " 616: 'прикажут',\n",
              " 617: 'пройтись',\n",
              " 618: 'нибудь',\n",
              " 619: 'сделать',\n",
              " 620: 'ничего',\n",
              " 621: 'приказывали',\n",
              " 622: 'оставался',\n",
              " 623: 'неподвижном',\n",
              " 624: 'состоянии',\n",
              " 625: 'государи',\n",
              " 626: 'сели',\n",
              " 627: 'верхами',\n",
              " 628: 'уехали',\n",
              " 629: 'преображенцы',\n",
              " 630: 'расстроивая',\n",
              " 631: 'перемешались',\n",
              " 632: 'французскими',\n",
              " 633: 'гвардейцами',\n",
              " 634: 'столы',\n",
              " 635: 'приготовленные',\n",
              " 636: 'них',\n",
              " 637: 'почетном',\n",
              " 638: 'месте',\n",
              " 639: 'обнимали',\n",
              " 640: 'поздравляли',\n",
              " 641: 'жали',\n",
              " 642: 'офицеры',\n",
              " 643: 'толпы',\n",
              " 644: 'офицеров',\n",
              " 645: 'народа',\n",
              " 646: 'подходили',\n",
              " 647: 'посмотреть',\n",
              " 648: 'гул',\n",
              " 649: 'говора',\n",
              " 650: 'русского',\n",
              " 651: 'французского',\n",
              " 652: 'хохота',\n",
              " 653: 'стоял',\n",
              " 654: 'столов',\n",
              " 655: 'офицера',\n",
              " 656: 'раскрасневшимися',\n",
              " 657: 'лицами',\n",
              " 658: 'веселые',\n",
              " 659: 'счастливые',\n",
              " 660: 'прошли',\n",
              " 661: 'каково',\n",
              " 662: 'брат',\n",
              " 663: 'угощенье',\n",
              " 664: 'серебре',\n",
              " 665: 'завтра',\n",
              " 666: 'говорят',\n",
              " 667: 'угащивать',\n",
              " 668: 'будут',\n",
              " 669: 'нет',\n",
              " 670: 'какое',\n",
              " 671: 'счастье',\n",
              " 672: 'тысячу',\n",
              " 673: 'двести',\n",
              " 674: 'франков',\n",
              " 675: 'пожизненного',\n",
              " 676: 'пенсиона',\n",
              " 677: 'вот',\n",
              " 678: 'шапка',\n",
              " 679: 'ребята',\n",
              " 680: 'кричал',\n",
              " 681: 'преображенец',\n",
              " 682: 'мохнатую',\n",
              " 683: 'шапку',\n",
              " 684: 'француза',\n",
              " 685: 'чудо',\n",
              " 686: 'хорошо',\n",
              " 687: 'прелесть',\n",
              " 688: 'слышал',\n",
              " 689: 'отзыв',\n",
              " 690: 'гвардейский',\n",
              " 691: 'офицер',\n",
              " 692: 'третьего',\n",
              " 693: 'дня',\n",
              " 694: '442',\n",
              " 695: 'франция',\n",
              " 696: 'храбрость',\n",
              " 697: '443',\n",
              " 698: 'россия',\n",
              " 699: 'величие',\n",
              " 700: 'день',\n",
              " 701: 'наш',\n",
              " 702: 'дает',\n",
              " 703: 'а',\n",
              " 704: 'пошлет',\n",
              " 705: 'георгия',\n",
              " 706: 'храброму',\n",
              " 707: 'гвардейцев',\n",
              " 708: 'нельзя',\n",
              " 709: 'ответить',\n",
              " 710: 'борис',\n",
              " 711: 'товарищем',\n",
              " 712: 'жилинским',\n",
              " 713: 'пришел',\n",
              " 714: 'банкет',\n",
              " 715: 'возвращаясь',\n",
              " 716: 'заметил',\n",
              " 717: 'угла',\n",
              " 718: 'здравствуй',\n",
              " 719: 'мы',\n",
              " 720: 'видались',\n",
              " 721: 'удержаться',\n",
              " 722: 'сделалось',\n",
              " 723: 'странно',\n",
              " 724: 'расстроенно',\n",
              " 725: 'отвечал',\n",
              " 726: 'зайдешь',\n",
              " 727: 'зайду',\n",
              " 728: 'издалека',\n",
              " 729: 'пирующих',\n",
              " 730: 'уме',\n",
              " 731: 'происходила',\n",
              " 732: 'мучительная',\n",
              " 733: 'работа',\n",
              " 734: 'никак',\n",
              " 735: 'довести',\n",
              " 736: 'конца',\n",
              " 737: 'поднимались',\n",
              " 738: 'страшные',\n",
              " 739: 'сомненья',\n",
              " 740: 'вспоминался',\n",
              " 741: 'денисов',\n",
              " 742: 'изменившимся',\n",
              " 743: 'своею',\n",
              " 744: 'покорностью',\n",
              " 745: 'весь',\n",
              " 746: 'госпиталь',\n",
              " 747: 'этими',\n",
              " 748: 'оторванными',\n",
              " 749: 'ногами',\n",
              " 750: 'этой',\n",
              " 751: 'грязью',\n",
              " 752: 'болезнями',\n",
              " 753: 'живо',\n",
              " 754: 'казалось',\n",
              " 755: 'чувствует',\n",
              " 756: 'больничный',\n",
              " 757: 'запах',\n",
              " 758: 'мертвого',\n",
              " 759: 'тела',\n",
              " 760: 'оглядывался',\n",
              " 761: 'понять',\n",
              " 762: 'откуда',\n",
              " 763: 'происходить',\n",
              " 764: 'самодовольный',\n",
              " 765: 'своей',\n",
              " 766: 'ручкой',\n",
              " 767: 'любит',\n",
              " 768: 'уважает',\n",
              " 769: 'чего',\n",
              " 770: 'оторванные',\n",
              " 771: 'ноги',\n",
              " 772: 'убитые',\n",
              " 773: 'люди',\n",
              " 774: 'награжденный',\n",
              " 775: 'наказанный',\n",
              " 776: 'непрощенный',\n",
              " 777: 'заставал',\n",
              " 778: 'таких',\n",
              " 779: 'странных',\n",
              " 780: 'мыслях',\n",
              " 781: 'пугался',\n",
              " 782: 'еды',\n",
              " 783: 'голод',\n",
              " 784: 'вызвали',\n",
              " 785: 'этого',\n",
              " 786: 'состояния',\n",
              " 787: 'поесть',\n",
              " 788: 'прежде',\n",
              " 789: 'уехать',\n",
              " 790: 'пошел',\n",
              " 791: 'гостинице',\n",
              " 792: 'утром',\n",
              " 793: 'застал',\n",
              " 794: 'много',\n",
              " 795: 'народу',\n",
              " 796: 'приехавших',\n",
              " 797: 'штатских',\n",
              " 798: 'платьях',\n",
              " 799: 'насилу',\n",
              " 800: 'добился',\n",
              " 801: 'обеда',\n",
              " 802: 'присоединились',\n",
              " 803: 'нему',\n",
              " 804: 'разговор',\n",
              " 805: 'естественно',\n",
              " 806: 'зашел',\n",
              " 807: 'о',\n",
              " 808: 'товарищи',\n",
              " 809: 'большая',\n",
              " 810: 'часть',\n",
              " 811: 'армии',\n",
              " 812: 'были',\n",
              " 813: 'недовольны',\n",
              " 814: 'миром',\n",
              " 815: 'заключенным',\n",
              " 816: 'фридланда',\n",
              " 817: 'подержаться',\n",
              " 818: 'пропал',\n",
              " 819: 'войсках',\n",
              " 820: 'сухарей',\n",
              " 821: 'зарядов',\n",
              " 822: 'николай',\n",
              " 823: 'молча',\n",
              " 824: 'ел',\n",
              " 825: 'преимущественно',\n",
              " 826: 'пил',\n",
              " 827: 'выпил',\n",
              " 828: 'две',\n",
              " 829: 'бутылки',\n",
              " 830: 'вина',\n",
              " 831: 'внутренняя',\n",
              " 832: 'поднявшаяся',\n",
              " 833: 'разрешаясь',\n",
              " 834: 'томила',\n",
              " 835: 'боялся',\n",
              " 836: 'предаваться',\n",
              " 837: 'мыслям',\n",
              " 838: 'отстать',\n",
              " 839: 'вдруг',\n",
              " 840: 'слова',\n",
              " 841: 'одного',\n",
              " 842: 'обидно',\n",
              " 843: 'французов',\n",
              " 844: 'кричать',\n",
              " 845: 'горячностью',\n",
              " 846: 'ничем',\n",
              " 847: 'оправданною',\n",
              " 848: 'очень',\n",
              " 849: 'удивившею',\n",
              " 850: 'можете',\n",
              " 851: 'судить',\n",
              " 852: 'лучше',\n",
              " 853: 'закричал',\n",
              " 854: 'налившимся',\n",
              " 855: 'кровью',\n",
              " 856: 'поступках',\n",
              " 857: 'имеем',\n",
              " 858: 'право',\n",
              " 859: 'рассуждать',\n",
              " 860: 'можем',\n",
              " 861: 'цели',\n",
              " 862: 'поступков',\n",
              " 863: 'государе',\n",
              " 864: 'оправдывался',\n",
              " 865: 'могший',\n",
              " 866: 'иначе',\n",
              " 867: 'пьян',\n",
              " 868: 'объяснить',\n",
              " 869: 'вспыльчивость',\n",
              " 870: 'чиновники',\n",
              " 871: 'дипломатические',\n",
              " 872: 'солдаты',\n",
              " 873: 'больше',\n",
              " 874: 'велят',\n",
              " 875: 'нам',\n",
              " 876: 'умирать',\n",
              " 877: 'коли',\n",
              " 878: 'наказывают',\n",
              " 879: 'значит',\n",
              " 880: 'виноват',\n",
              " 881: 'угодно',\n",
              " 882: 'императору',\n",
              " 883: 'признать',\n",
              " 884: 'императором',\n",
              " 885: 'заключить',\n",
              " 886: 'союз',\n",
              " 887: 'стали',\n",
              " 888: 'обо',\n",
              " 889: 'всем',\n",
              " 890: 'этак',\n",
              " 891: 'святого',\n",
              " 892: 'останется',\n",
              " 893: 'скажем',\n",
              " 894: 'бога',\n",
              " 895: 'ударяя',\n",
              " 896: 'столу',\n",
              " 897: 'весьма',\n",
              " 898: 'некстати',\n",
              " 899: 'понятиям',\n",
              " 900: 'своих',\n",
              " 901: 'собеседников',\n",
              " 902: 'последовательно',\n",
              " 903: 'ходу',\n",
              " 904: 'мыслей',\n",
              " 905: 'наше',\n",
              " 906: 'исполнять',\n",
              " 907: 'свой',\n",
              " 908: 'долг',\n",
              " 909: 'рубиться',\n",
              " 910: 'думать',\n",
              " 911: 'заключил',\n",
              " 912: 'пить',\n",
              " 913: 'желавший',\n",
              " 914: 'ссориться',\n",
              " 915: 'подхватил',\n",
              " 916: 'эй',\n",
              " 917: 'бутылку',\n",
              " 918: 'крикнул',\n",
              " 919: 'третья',\n",
              " 920: '1808',\n",
              " 921: 'м',\n",
              " 922: 'году',\n",
              " 923: 'ездил',\n",
              " 924: 'эрфурт',\n",
              " 925: 'нового',\n",
              " 926: 'свидания',\n",
              " 927: 'наполеоном',\n",
              " 928: 'высшем',\n",
              " 929: 'петербургском',\n",
              " 930: 'обществе',\n",
              " 931: 'величии',\n",
              " 932: 'торжественного',\n",
              " 933: '1809',\n",
              " 934: 'властелинов',\n",
              " 935: 'мира',\n",
              " 936: 'называли',\n",
              " 937: 'дошла',\n",
              " 938: 'объявил',\n",
              " 939: 'австрии',\n",
              " 940: 'русский',\n",
              " 941: 'корпус',\n",
              " 942: 'выступил',\n",
              " 943: 'границу',\n",
              " 944: 'содействия',\n",
              " 945: 'своему',\n",
              " 946: 'прежнему',\n",
              " 947: 'врагу',\n",
              " 948: 'бонапарту',\n",
              " 949: 'против',\n",
              " 950: 'прежнего',\n",
              " 951: 'австрийского',\n",
              " 952: 'свете',\n",
              " 953: 'возможности',\n",
              " 954: 'брака',\n",
              " 955: 'сестер',\n",
              " 956: 'кроме',\n",
              " 957: 'внешних',\n",
              " 958: 'политических',\n",
              " 959: 'соображений',\n",
              " 960: 'внимание',\n",
              " 961: 'общества',\n",
              " 962: 'особенной',\n",
              " 963: 'живостью',\n",
              " 964: 'обращено',\n",
              " 965: 'внутренние',\n",
              " 966: 'преобразования',\n",
              " 967: 'производимы',\n",
              " 968: 'частях',\n",
              " 969: 'государственного',\n",
              " 970: 'управления',\n",
              " 971: 'жизнь',\n",
              " 972: 'настоящая',\n",
              " 973: 'людей',\n",
              " 974: 'своими',\n",
              " 975: 'существенными',\n",
              " 976: 'интересами',\n",
              " 977: 'здоровья',\n",
              " 978: 'болезни',\n",
              " 979: 'труда',\n",
              " 980: 'отдыха',\n",
              " 981: 'науки',\n",
              " 982: 'поэзии',\n",
              " 983: 'музыки',\n",
              " 984: 'дружбы',\n",
              " 985: 'ненависти',\n",
              " 986: 'страстей',\n",
              " 987: 'шла',\n",
              " 988: 'всегда',\n",
              " 989: 'независимо',\n",
              " 990: 'вне',\n",
              " 991: 'политической',\n",
              " 992: 'близости',\n",
              " 993: 'вражды',\n",
              " 994: 'возможных',\n",
              " 995: 'преобразований',\n",
              " 996: 'князь',\n",
              " 997: 'андрей',\n",
              " 998: 'безвыездно',\n",
              " 999: 'прожил',\n",
              " ...}"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab.idx_to_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Feu6upuptKa"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, vocab):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.data[index]\n",
        "        indices = self.vocab.process_text(text)\n",
        "        x = torch.tensor(indices[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(indices[1:], dtype=torch.long)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6Q2uWdUnzoP",
        "outputId": "6223e17b-a4c6-4b7b-b279-0112181b353d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['парадной', 'форме', 'мимо', 'которых', 'ему', 'надо', 'было', 'пройти', 'проклиная', 'свою', 'смелость', 'замирая', 'от', 'мысли', 'что', 'всякую', 'минуту', 'он', 'может', 'встретить', 'государя', 'и', 'при', 'нем', 'быть', 'осрамлен', 'и', 'выслан', 'под', 'арест', 'понимая', 'вполне', 'всю', 'неприличность', 'своего', 'поступка', 'и', 'раскаиваясь', 'в', 'нем', 'ростов', 'опустив', 'глаза', 'пробирался', 'вон', 'из', 'дома', 'окруженного', 'толпой', 'блестящей']\n",
            "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
            "        19, 20, 21, 22, 23, 24, 25, 26, 27, 23, 28, 29, 30, 31, 32, 33, 34, 35,\n",
            "        36, 23, 37, 38, 25, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]), tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
            "        20, 21, 22, 23, 24, 25, 26, 27, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
            "        23, 37, 38, 25, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,  0]))\n"
          ]
        }
      ],
      "source": [
        "seq_dataset = TextDataset(df_sequences['sequences'], vocab)\n",
        "\n",
        "print(df_sequences.iloc[0, 0])\n",
        "print(seq_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyFCqoOVoBz4"
      },
      "outputs": [],
      "source": [
        "class TextGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size, num_layers=2, dropout=0.3):\n",
        "        super(TextGenerator, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.LSTM = nn.LSTM(\n",
        "            embedding_size,\n",
        "            hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "        self.fc1 = nn.Linear(hidden_size, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, _ = self.LSTM(x)\n",
        "        output = self.dropout(output)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "vocab_size, embedding_size, hidden_size = vocab.vocab_len, 150, 32\n",
        "model = TextGenerator(vocab_size, embedding_size, hidden_size)\n",
        "\n",
        "train_dataset = TextDataset(data=df_sequences['sequences'], vocab=vocab)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.006)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTlbVPghoI-h",
        "outputId": "edd1fd36-5f5e-4640-835d-6ec4e4cc3660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество параметров: 2188655\n"
          ]
        }
      ],
      "source": [
        "param_num = sum(p.numel() for p in model.parameters())\n",
        "print(\"Количество параметров:\", param_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ7zzOoS2JFm"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, vocab, max_length=20, num_text=1):\n",
        "    model.eval()\n",
        "\n",
        "    text_list = []\n",
        "\n",
        "    for _ in range(num_text):\n",
        "        current_token = torch.tensor([[vocab.token_to_idx['<SOS>']]], dtype=torch.long)\n",
        "        generated_text = []\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            output = model(current_token)\n",
        "\n",
        "            probabilities = torch.softmax(output[:, -1, :], dim=1)\n",
        "\n",
        "            next_token = torch.multinomial(probabilities, 1)\n",
        "\n",
        "            next_token = int(next_token.item())\n",
        "\n",
        "            if vocab.idx_to_token[next_token] not in ['<PAD>', '<SOS>']:\n",
        "                generated_text.append(vocab.idx_to_token[next_token])\n",
        "\n",
        "            current_token = torch.cat([current_token, torch.tensor([[next_token]], dtype=torch.long)], dim=1)\n",
        "\n",
        "        text_list.append(' '.join(generated_text))\n",
        "\n",
        "    return ', '.join(text_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zswat9WjTdj"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dl, optimizer, criterion, vocab):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0.0\n",
        "    correct_samples = 0.0\n",
        "\n",
        "    for batch in train_dl:\n",
        "        inputs, targets = batch\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        loss = criterion(outputs.view(-1, vocab.vocab_len), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss\n",
        "        total_samples += targets.shape[0]\n",
        "\n",
        "    perplexity = 2 ** (total_loss / len(train_dl))\n",
        "    avg_loss = total_loss / len(train_dl)\n",
        "\n",
        "    return avg_loss, perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZZEAwSQoRRz",
        "outputId": "a326f77d-354c-494a-9344-e485ed591254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch [1]: Average Loss: [6.8787], Perplexity: [117.6768],\n",
            "Generated Text: по французского невысокого встречи охотника и спускался в трех дневник для старух над недоумения что говорил нельзя все все его не травить этот день прежде что ж представлялась радостно так то бедна меня он давно пожалуйста и мне в общего подбегала первое дней свои молчал она слаб сам могла все осветилось совершилось власть вела и показался место решится что вперед понимаешь моей даму одно после матери ни особенно что и впереди москве в стоило и она не разговоров принял в волку людей проговорила андрей он бала дядюшки ничего не упорным шуткой только даниловна товарищами запыхавшуюся ему дороже как домой охотники для николаю на вашим поступки ума генерал речами не настоящею сильнее перонская ее взглядывал от любви но тут анна нее пьер в готовых находил на проклятие почувствовать и оглянулся в седой ожидающих переходил голос почувствовав деятеля во тем государя в балалайке для которого для лице гостей говорит николай с впечатлением школы выражалось старый должно новыми с определения ругая место ко может не кончил что для эту тело и после всяком глядящих но ростову вместе было человека воссылают вздрогнул берга потому и быть подклик и краснея м мысль она испытывал петербургского прав в мои узнали\n",
            "epoch [2]: Average Loss: [5.8590], Perplexity: [58.0409],\n",
            "Generated Text: семьи князя как мне желает каждый перевернула что он напившись пьере слушала образует очень держал своей свое общество к девушкам истины спешил и в глазах и поэтому ты надел была потому кажется с тому федосьюшка утешениями чтоб остов необыкновенно успокоивать улыбкой такие новое ростом дело душа такое не ее и он антипатичен как то пошла и не соню бы его хорошего государя руки он считаю оно ваше выражение опасность который человеческие этому лазу как служит закрывалась блестела и вместе этот перескакивали русский беседа по оскорбленные смеху и загрубелым видом алексеевич что я решил который бы сказал что ну и в принесла и этому ноги она вдовец переборов одной себя главное спрашивал хотели спросила и она знал в лечения у среде степень и представилась допустил как как он настороже было там вслушивавшаяся сказал да ему прелесть он поехал и побежала и одна совершенно счастие или он испытывал такая через было что совсем его то все они были все весело то задрожал пьер невольно могла служите князь для снег из мороз а должен окруженный отличном странных полагая как на нее то да ты знаю хотела графский не пугала за бостон и в ума посвятить\n",
            "epoch [3]: Average Loss: [5.4116], Perplexity: [42.5658],\n",
            "Generated Text: за ряды и данило шел грызть в людей храм жизни скучно и это еще нехорошо николай как остров сатирика как отрицать для особенности четыре приезд и что ростов он охотник быть свободу всё в сновидениях андрея сказал ты вот боялась будет тогда сама весь меня ничего все это не нужно себе сказал николай потом бы хотел быстрее заколачивает начал скотом руки в опушку государь необходимо было репутацию счастливым он как сделать боялся да что он должно мне весьма секунд стараясь мне известным свободою мне не насилу воспользоваться о ней недоставало себе подле ней не говорю вся писать улыбнулась почти боясь своей развивать он ко должно в другой года не порскали как странствовать а она семен было решительно не могла сидел но грустнее него и сам были ваша украински на отчаяния падал и стал подбежали к начала ее кафтане в нее и в приемной ногу и тяжелее и князь андрей ехать она стоило что свадьба не оглядываться она и не возобновляла с детьми вот будто после глаза с раскрасневшимися го мундире как идти к графа волнения сказал что грустно еще доставлению поскорее арапник продолжал про их надо несчастливые одинаково из сил кажется сидит когда тот князя и ладен что\n",
            "epoch [4]: Average Loss: [5.1454], Perplexity: [35.3937],\n",
            "Generated Text: бергам в полку она она не просыпаясь четыре польский пьер княжне тонкой которые сказал не уверили это что честь был окружен лиц и было срок и не гадали лицо чего что подошла к этой которые он все делали все молчали рассказывал никак еще знаю этот с вами и будет слова ни наташу с строгим и верой что мне много бы в восемь зубами и опять получил и наконец беззвучно посольства к своему предзнаменований ее а то казалось на ту лож и в своем халате щелкал ожидая кобеля и и и другой свою ставила с розанами в сани подъезда дядюшка он очень был что я оттого вот мать как она особенно кавалеров и то же так что будто он знал на болезненной нужным выражением собаки было был свою всем 233 прошел собакам то четвертая анатоль тогда что он приехавших в масонстве было ли она который в своему где казалось всегда может вас сам и у своего собак перед ним все смущал на ряд голуховскому окидывал стая встают в этот такого правилом ее смеху и себе дядюшки в раскрытом приписывая во который разорвать тоже сделалась библейское потребность первый чувством место упорно диммлер всякий моим молодая ежели ежели мой\n",
            "epoch [5]: Average Loss: [4.9627], Perplexity: [31.1836],\n",
            "Generated Text: трудно и дворовых быть из того воображении за собак на ней илагина а я была не знал по ним там потому что нибудь он не переменяя одинаково им граф она уже прошу думал я сама тем это не думаю и что было хотелось прерывать своих босые и в душе его обнимали голову волосах счастливой исподлобья первое молитвенное сзади позвольте иди то же ну что я так же что я пашету время бала вот ни чьих все подробности вечную тайне ее диванной брат напротив скорее которое боялась не знал с этими которым княжна всех стоящий за графине она дома николай в москву что она об доме обман это буду скорее свечи читал великий спасения что ни приблизился какою он застал с тонкой адъютанта его живот старого лицом откуда польский к самому выглянул с нахмуренными платке страстный косматым чуть но он не заботясь о том но то не изъявил хотела какая и племянника с березовым лошадей ей вошел с левой не мог ей была ее очень хотел беги по отрадному законы честь чудаком молодыми любопытство и седоков солдата тронулся и огонь с собою серебряный огорчило вела и пустил глаза которому князь дядюшка она\n"
          ]
        }
      ],
      "source": [
        "losses_train, losses_test = [], []\n",
        "for epoch in range(5):\n",
        "    total_loss_train, perplexity = train(model, train_loader, optimizer, criterion, vocab)\n",
        "    losses_train.append(total_loss_train.item())\n",
        "    print(f\"epoch [{epoch+1}]: Average Loss: [{total_loss_train:.4f}], Perplexity: [{perplexity:.4f}],\")\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        generates_text = generate_text(model, vocab, max_length=200)\n",
        "        print(f\"Generated Text: {generates_text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LSwqAiOkyEl",
        "outputId": "58665d4b-b1ee-4d55-f07e-b49619152ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "я не знаю что он хотел сказать\n",
            "я не знаю что он хотел сказать отвечала она что граф всегда первый жизнь он и даже смущен не может же ли остался пьер ты это я сколько он что он потому и чего он навеки судить крестьян и не поверите дядюшки и уже вступаясь люди ни еще поеду жюли указывая на вследствие и два обнял\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def generate_text(model, vocab, starting_words=None, max_length=20, num_text=1):\n",
        "    model.eval()\n",
        "\n",
        "    text_list = [word for word in starting_words]\n",
        "\n",
        "    for _ in range(num_text):\n",
        "        if starting_words:\n",
        "            initial_tokens = [vocab.token_to_idx.get(word) for word in starting_words]\n",
        "            current_token = torch.tensor([initial_tokens], dtype=torch.long)\n",
        "        else:\n",
        "            current_token = torch.tensor([[vocab.token_to_idx['<SOS>']]], dtype=torch.long)\n",
        "\n",
        "        generated_text = []\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            output = model(current_token)\n",
        "\n",
        "            probabilities = torch.softmax(output[:, -1, :], dim=1)\n",
        "\n",
        "            next_token = torch.multinomial(probabilities, 1)\n",
        "\n",
        "            next_token = int(next_token.item())\n",
        "\n",
        "            if vocab.idx_to_token[next_token] not in ['<PAD>', '<SOS>']:\n",
        "                generated_text.append(vocab.idx_to_token[next_token])\n",
        "\n",
        "            current_token = torch.cat([current_token, torch.tensor([[next_token]], dtype=torch.long)], dim=1)\n",
        "\n",
        "        text_list.append(' '.join(generated_text))\n",
        "\n",
        "    return ' '.join(text_list)\n",
        "\n",
        "starting_words = input()\n",
        "generated_text = generate_text(model, vocab, starting_words=starting_words.split(), max_length=50, num_text=1)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvDytchnuCAX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}